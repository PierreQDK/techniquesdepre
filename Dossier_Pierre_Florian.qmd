---
title: "Dossier"
author: "Pierre et Florian"
format:
  html:
    toc: true
    toc-title: Sommaire
    code-fold: true
    echo: true
    eval: true
    incremental: true
  pdf:
    toc: true
    toc-title: Sommaire
    echo: true
    eval: true
  revealjs:
    incremental: true
---

Choix 2 : Série CVS  ou non saisonnière mensuelle 
(Possibilité d’utiliser la série du dossier cours « Séries temporelles univariées »)  

```{r}
# Importation des librairies

library(tidyquant)
library(tidyverse)
library(forecast)
```

# 1. Analyse préliminaire

## a. Présentation et caractérisation de la série étudiée : source, définition, graphique


### 1. Présentation

```{r}
# Importation des données

cac40 <- tq_get(
  "^FCHI",
  from = "2000-01-01", to = "2019-12-31", periodicity = "monthly"
) |>
  mutate(
    date = date %m+% months(1)
  ) |>
  select(
    date, close
  ) |>
  rename(
    cloture = close
  )

head(cac40, n = 20)
```


La série de données utilisée dans cette analyse provient du site Yahoo Finance (https://finance.yahoo.com/), une plateforme de référence pour les données financières et boursières.

Elle concerne l’indice CAC 40, qui regroupe les 40 plus grandes entreprises françaises cotées à la Bourse de Paris. Cet indice est un indicateur clé de la performance des marchés financiers en France.

La série temporelle mensuelle commence en janvier 2000 et se termine en décembre 2019, couvrant ainsi une période de 20 ans.


```{r}
# Classe time series
cac40_ts <- ts(data = cac40$cloture, start = c(2000, 01), frequency = 12)

plot.ts(cac40_ts)
```


### 2. Caractéristiques (saisonnalité ?)

```{r}
# Seasonal dummies
library(TSA)
sd <- seasdum(cac40_ts)
show(sd)
```

Le test des variables muettes saisonnières (seasdum) a été appliqué à la série temporelle cac40_ts afin de détecter la présence d’une composante saisonnière. La statistique de test obtenue est de 1,47, avec une p-value associée de 0,1445. Cette p-value étant supérieure aux seuils usuels de signification (5 % ou même 10 %), on ne rejette pas l’hypothèse nulle d’absence de saisonnalité. Cela signifie qu’il n’existe pas de preuve statistique suffisante pour affirmer que la série CAC 40 présente une variation régulière et récurrente selon les périodes (mois, trimestres, etc.).


```{r}
# Webel-Ollech test - new version of seastests (2021-09)
wot <- combined_test(cac40_ts)
show(wot)
```

Le test combiné de type WO (combined_test) a été réalisé pour détecter des effets saisonniers ou calendaire multiples dans la série cac40_ts. La statistique de test globale est de 0, avec des p-values respectives de 1, 1 et 0,1039 pour les différents sous-tests. La p-value finale étant légèrement supérieure à 10 %, on ne rejette pas non plus l’hypothèse nulle d’absence d’effet saisonnier ou calendaire. Ainsi, ce test ne met pas en évidence de structure saisonnière marquée ni d’effet lié à des facteurs calendaires dans la série analysée.


## b. Détection des points atypiques. Présenter ces points sous forme de tableau (date, type de point (AO, TC …), t-stat) et trouver des explications économiques de l’apparition des 3 plus importants 

### 1. Première détection

```{r}
# Détection

library(tsoutliers)

ajustement1 <- tso(cac40_ts)
plot(ajustement1)
show(ajustement1)
```

En janvier 2008 (97e observation de la série), le modèle détecte un changement négatif de niveau (LS) important sur le CAC 40, de l’ordre de –726 points. Il s'agit d’un point atypique structurel dans la série.
Cette chute brutale de niveau subie par le CAC 40 en janvier 2008 correspond très probablement au début de la crise financière mondiale des subprimes. Le marché avait commencé à anticiper l'effondrement des banques, ce qui a provoqué une forte baisse des indices boursiers.


```{r}
# Série corrigée des points atypiques

cac40_ts <- ajustement1$yadj
plot(cac40_ts)
```



### 2. Deuxième détection

```{r}
# Détection

ajustement2 <- tso(cac40_ts)
plot(ajustement2)
show(ajustement2)
```

En septembre 2001 (21e observation de la série), le modèle détecte un changement transitoire de niveau (TC) significatif sur le CAC 40, d’environ –639 points. Ce type d’anomalie indique un effet temporaire qui se dissipe progressivement dans le temps. Cet événement correspond très probablement aux attentats du 11 septembre 2001, qui ont provoqué une forte chute temporaire des marchés financiers mondiaux, marqués par un choc d'incertitude et de panique.

Un an plus tard, en septembre 2002 (33e observation), le modèle identifie un point atypique (AO) d’environ –517 points. Il s'agit d'un choc ponctuel avec un impact direct et isolé sur le niveau du CAC 40. Cette anomalie pourrait refléter une crise de confiance persistante, alimentée par la prolongation des effets économiques post-11 septembre et par les scandales financiers majeurs, notamment Enron (2001) et WorldCom (2002), qui ont fortement affecté la crédibilité des marchés financiers et contribué à la volatilité de l’époque.


```{r}
# Série corrigée des points atypiques

cac40_ts <- ajustement2$yadj
plot(cac40_ts)
```


### 3. Troisième détection

```{r}
# Détection

ajustement3 <- tso(cac40_ts)
plot(ajustement3)
show(ajustement3)
```

Aucun point atypique détecté.


## c. Vérifier la stationnarité de la série I(0) ou I(1)

### 1. Tests

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Chargement des bibliothèques nécessaires
library(tseries)
library(urca)

# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  cac40_ts, 
  type = "drift", 
  selectlags = "AIC"
)
summary(adf_test)
```

Le test de Dickey-Fuller augmentée (ADF) permet de tester l'hypothèse nulle selon laquelle la série temporelle possède une racine unitaire, ce qui indique une non-stationnarité. Dans les résultats, le test ADF fournit une statistique de test de -1.4688, qui est supérieure aux valeurs critiques à 1% (-3.46), 5% (-2.88) et 10% (-2.57). Cela indique que nous ne rejetons pas l'hypothèse nulle au seuil de 5%, ce qui suggère que la série temporelle présente une racine unitaire et n'est donc pas stationnaire. En outre, la p-value associée à l’estimation de la pente du modèle (0.143) confirme l’absence de significativité du test, renforçant ainsi l’idée de non-stationnarité.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  cac40_ts, 
  type = "Z-tau", 
  model = "constant", 
  lags = "short"
)
summary(pp_test)
```

Le test de Phillips et Perron (PP) est également utilisé pour tester la présence d'une racine unitaire dans une série temporelle, mais il est moins sensible aux problèmes d'hétéroscédasticité. Dans ce cas, la statistique de test Z-tau est -1.3614, ce qui est également supérieur aux valeurs critiques à 1% (-3.4591), 5% (-2.8737) et 10% (-2.5732). Cela indique, tout comme pour le test ADF, que nous ne rejetons pas l'hypothèse nulle et que la série temporelle n'est pas stationnaire. La p-value pour le coefficient de la variable retardée (< 2e-16) est très significative, indiquant que la série temporelle suit un modèle autorégressif, mais cela ne suffit pas à conclure à la stationnarité.


#### 3. Test de KPSS

```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  cac40_ts, 
  type = "mu"
)
summary(kpss_test)
```

Le test de KPSS (Kwiatkowski-Phillips-Schmidt-Shin) teste l'hypothèse nulle selon laquelle la série est stationnaire. La statistique de test est de 1.1633, qui est bien au-dessus des valeurs critiques pour le niveau de signification de 1%, 5% et 10% (0.739, 0.463, 0.347 respectivement). Cela suggère que nous rejetons l'hypothèse nulle de stationnarité au seuil de 5%, ce qui appuie la conclusion que la série temporelle est non stationnaire. Cette conclusion est cohérente avec les résultats des tests ADF et PP.


#### 4. Conclusion

Les résultats des trois tests unitaires (ADF, PP, et KPSS) indiquent que la série temporelle étudiée, en l'occurrence le CAC40, n'est pas stationnaire. Le test ADF et le test PP, tous deux basés sur l'hypothèse de non-stationnarité, n'ont pas permis de rejeter cette hypothèse, et le test KPSS a montré des preuves contraires à la stationnarité. Ces tests convergent vers la même conclusion : la série présente probablement une racine unitaire, ce qui nécessite probablement une différenciation pour la rendre stationnaire avant d'effectuer toute modélisation.



### 2. Différenciation de la série

```{r}
# 1. Différencier la série
diff_cac40_ts <- diff(cac40_ts)
ts.plot(diff_cac40_ts)
```


### 3. Tester la stationnarité après différenciation

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  diff_cac40_ts, 
  type = "none", 
  selectlags = "AIC"
)
summary(adf_test)
```

Après différenciation de la série temporelle, la statistique du test ADF est de -11.2216, bien inférieure aux valeurs critiques à 1%, 5% et 10% (-2.58, -1.95, -1.62, respectivement). La p-value associée est inférieure à 2e-16, ce qui permet de rejeter l'hypothèse nulle de racine unitaire. Cela suggère que la série devient stationnaire après différenciation, ce qui est cohérent avec l'idée que la non-stationnarité observée initialement pourrait être résolue par la différenciation.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  diff_cac40_ts, 
  type = "Z-tau", 
  model = "constant", 
  lags = "short"
)
summary(pp_test)
```

Le test PP montre une statistique Z-tau de -14.6639, bien inférieure aux valeurs critiques à 1%, 5% et 10% (-3.459, -2.874, -2.573). De plus, la p-value pour le coefficient retardé est de 0.324, ce qui signifie que l'on ne peut pas rejeter l'hypothèse nulle d'absence de racine unitaire uniquement sur cette base. Toutefois, la valeur très faible de la statistique Z-tau permet de conclure que, après différenciation, la série devient stationnaire, appuyant ainsi l'idée que la série est désormais stabilisée et ne présente plus de racine unitaire.


#### 3. Test de KPSS

```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  diff_cac40_ts, 
  type = "mu"
)
summary(kpss_test)
```

Le test de KPSS donne une statistique de test de 0.2208, qui est inférieure aux valeurs critiques à 1%, 5% et 10% (0.739, 0.463, 0.347 respectivement). Cela indique que nous ne rejetons pas l'hypothèse nulle de stationnarité de la série après différenciation. Ce résultat renforce les conclusions des tests ADF et PP, montrant que la série est devenue stationnaire après différenciation.


#### 4. Conclusion

Après la différenciation de la série temporelle, les trois tests unitaires (ADF, PP, et KPSS) confirment que la série devient stationnaire. Le test ADF et le test PP rejettent l'hypothèse de racine unitaire, tandis que le test KPSS ne rejette pas l'hypothèse de stationnarité. Ces résultats indiquent que la différenciation a permis de rendre la série temporelle stationnaire, ce qui est une étape clé avant toute modélisation ou analyse plus approfondie.


### 4. Corrélogrammes

```{r}
library(gridExtra)

# Corrélogramme

acf_graph1 <- cac40_ts |> 
  ggAcf() +
  ggtitle("Corrélogramme sur la série en niveau") +
  theme_bw()

acf_graph2 <- diff_cac40_ts |>  
  ggAcf() +
  ggtitle("Corrélogramme sur la série en différence première") +
  theme_bw()

grid.arrange(acf_graph1, acf_graph2, ncol = 2)
```

Avant la différenciation, la série, non stationnaire (comme une série intégrée I(1)), présente une autocorrélation significative sur les premiers retards, ce qui suggère la présence d'une racine unitaire et l'absence de stationnarité. Après la différenciation, l'ACF montre une légère autocorrélation au troisième retard, avec des autocorrélations non significatives pour les autres retards, ce qui indique que la série est devenue stationnaire (I(0)). Ainsi, l'ACF de la série différenciée ne présente plus d'autocorrélations significatives, à l'exception d'une autocorrélation résiduelle éventuelle au troisième retard, suggérant que la différenciation a éliminé la non-stationnarité, rendant la série adaptée à des analyses économétriques.


## d. Statistiques descriptives (moyenne, écart-type, skewness, kurtosis normalité, box-plot …). (cf. Chapitre 3 p38) Commenter

### 1. Statistiques

```{r}
library(fBasics)

stats <- basicStats(diff_cac40_ts)
show(stats)
```


### 2. Normalité

```{r}
shapiro.test(diff_cac40_ts)
```

La p-value de 0.01046, inférieure au seuil de 5 %, indique que l'hypothèse nulle de normalité est rejetée au seuil de risque de 5 %. Cela signifie que les données ne suivent pas une distribution normale. Ainsi, la série différenciée du CAC 40 n'est pas normalement distribuée d'après le test de Shapiro-Wilk.


### 3. Boîte à moustache

```{r}
boxplot(
  diff_cac40_ts,
  main = "Boîte à moustaches de la série différenciée",
  ylab = "Valeurs différenciées",
  col = "lightblue"
)
```

Nous observons plusieurs valeurs potentiellement atypiques.
Nous devons vérifier si ces valeurs sont réellement atypiques.


```{r}
library(EnvStats)
rosnerTest(diff_cac40_ts, k = 10, alpha = 0.05)
```

D'après le test de Rosner, ces valeurs ne sont pas considérées comme atypiques.



# 2. Estimation des modèles linéaires

## a. Estimer et commenter les paramètres des modèles AR(1), AR(p) et ARIMA(p,d,q) et de la méthode LED Holt-Winters, ADAM ETS, ADAM ETS ARIMA, SSARIMA et CES 

# POSER AU PROF LA QUESTION : devons-nous utiliser les séries différenciées en fonction du modèle ?

###  2.1 - AR(1)

```{r}
library(forecast)
mod_ar1 <- Arima(diff_cac40_ts, order = c(1,0,0))
summary(mod_ar1)
```


### 2.2 - AR(p)

```{r}
mod_arp <- ar(diff_cac40_ts, aic=TRUE, order.max=12)
mod_arp$order
mod_arp$ar
```

```{r}
library(tibble)
library(purrr)
library(forecast)
library(tidyr)

# Liste des ordres
ordre_p <- 1:10

# Estimation des modèles AR(p)
mods_arp <- map(ordre_p, ~ Arima(diff_cac40_ts, order = c(.x, 0, 0)))

# Tableau
resultat_arp <- tibble(
  modele = paste0("AR(", ordre_p, ")"),
  mean = map_dbl(mods_arp, ~ coef(.x)["intercept"]),
  ar1 = map_dbl(mods_arp, ~ coef(.x)["ar1"]),
  ar2 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 2, coef(.x)["ar2"], NA_real_)),
  ar3 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 3, coef(.x)["ar3"], NA_real_)),
  ar4 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 4, coef(.x)["ar4"], NA_real_)),
  ar5 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 5, coef(.x)["ar5"], NA_real_)),
  ar6 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 6, coef(.x)["ar6"], NA_real_)),
  ar7 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 7, coef(.x)["ar7"], NA_real_)),
  ar8 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 8, coef(.x)["ar8"], NA_real_)),
  ar9 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 9, coef(.x)["ar9"], NA_real_)),
  ar10 = map_dbl(mods_arp, ~ ifelse(.x$arma[1] >= 10, coef(.x)["ar10"], NA_real_)),
  aic = map_dbl(mods_arp, ~ AIC(.x)),
  aicc = map_dbl(mods_arp, ~ AICc(.x))
) |> 
  pivot_longer(cols = -modele, names_to = "parametre", values_to = "valeur") |> 
  pivot_wider(names_from = "modele", values_from = "valeur")

resultat_arp

# View(resultat_arp)
```


### 2.3 - Autoarima

```{r}
mod_arima <- auto.arima(cac40_ts)
summary(mod_arima)
```


### 2.4 - Lissage Exponentiel Double (LED) de Holt-Winters

```{r}
# ---- Modélisation ----

# Modèle LED Holt-Winters : lissage exponentiel double (niveau + tendance)
m <- HoltWinters(cac40_ts, gamma = FALSE)

# ---- prévision ----

# Prévision sur un horizon h = 50 avec intervalles de confiance à 80% et 95%
fit <- forecast(m, h = 50) # ← prévision à 50 périodes
plot(fit)
show(fit)

# Prévisions ponctuelles
prevf <- fit$mean # ← point de prévision
show(prevf)

# Informations sur le modèle ajusté
mod <- fit$model
show(mod)
```


### 2.5 - ADAM ETS (Error-Trend-Seasonal)

```{r}
# Chargement de la librairie
library(smooth)

# Estimation du modèle ADAM ETS (ZZZ = sélection automatique)
fit_adam_ets <- auto.adam(
  cac40_ts,              # série mensuelle CAC 40
  model = "ZZZ",         # sélection automatique de la structure ETS
  lags = c(1, 12),       # court terme et saisonnalité mensuelle
  select = TRUE          # sélection selon l'AIC
)

# Prévision à 12 mois avec intervalle de confiance à 90 %
prev_adam_ets <- forecast(fit_adam_ets, h = 12, level = 0.90)

# Affichage des prévisions
plot(prev_adam_ets)

# Aperçu des valeurs prédites
prev_adam_ets

```


### 2.6 - ADAM ETS-ARIMA (modèle hybride)

```{r}
# Modèle ADAM ETS + ARIMA
library(smooth)

fit_adam_ets_arima <- auto.adam(
  cac40_ts,                          # série CAC 40 en niveau
  model = "ZZZ",                     # sélection automatique ETS
  lags = c(1, 1, 12),                # lags pour tendance, ARIMA, saisonnalité
  orders = list(
    ar = c(3, 3),                    # ordres AR non saisonnier / saisonnier
    i  = c(2),                       # ordre de différenciation
    ma = c(3, 3)                     # ordres MA non saisonnier / saisonnier
  ),
  select = TRUE                     # sélection automatique du meilleur sous-modèle
)

# Prévision sur 12 mois avec IC à 90 %
prev_adam_ets_arima <- forecast(fit_adam_ets_arima, h = 12, level = 0.90)

# Affichage des prévisions
prev_adam_ets_arima
plot(prev_adam_ets_arima)

```


### 2.7 - SSARIMA (State Space ARIMA)

```{r}
# Modèle SSARIMA
library(smooth)

fitssarima <- auto.ssarima(
  cac40_ts, # série utilisée
  lags = c(1, 12), # spécifie une structure SARIMA mensuelle
  orders = list(
    ar = c(3, 3), # ordre max AR non saisonnier et saisonnier
    i = c(2), # ordre max de différenciation
    ma = c(3, 3)
  ), # ordre max MA non saisonnier et saisonnier
  select = TRUE # sélection automatique du meilleur modèle
)

summary(fitssarima)

# Graphiques
par(mfcol = c(2, 2))
plot(fitssarima)

# Prévision sur 12 mois (avec IC à 90 %)
prevssarima <- forecast(fitssarima, h = 12, level = 0.90) # ← prévision du modèle SSARIMA pour h = 12
plot(prevssarima)
```

### 2.8 - CES (Complex Exponential Smoothing)

```{r}
# Modèle CES (Complex Exponential Smoothing)
library(smooth)

# Estimation automatique du meilleur modèle CES
mod_ces <- auto.ces(
  cac40_ts, # série temporelle utilisée
)

# Résumé des paramètres estimés, AIC, erreurs, etc.
summary(mod_ces)

# Graphiques de diagnostic (décomposition, résidus, QQ-plot, etc.)
par(mfrow = c(2, 2)) # disposition des 4 graphiques
plot(mod_ces)

# Prévision sur 12 périodes avec intervalle à 95 %
prev_ces <- forecast(mod_ces, h = 12, level = 0.95)

# Graphique des prévisions avec intervalle de confiance
plot(prev_ces)
```







# 3. Prévision linéaire sur une année 

```{r}
# Données d'apprentissage jusqu'à 2013
cac40_train_2013 <- window(cac40_ts, end = c(2013, 12))
cac40_test_2014  <- window(cac40_ts, start = c(2014, 1), end = c(2014, 12))

# Ré-estimation des modèles
fit_adam_2013 <- auto.adam(cac40_train_2013, model = "ZZZ", lags = c(1, 12), select = TRUE)
fit_adamarima_2013 <- auto.adam(cac40_train_2013, model = "ZZZ", lags = c(1, 1, 12),
                                orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_arima_2013 <- auto.arima(cac40_train_2013)
fit_hw_2013 <- HoltWinters(cac40_train_2013, gamma = FALSE)
fit_ssarima_2013 <- auto.ssarima(cac40_train_2013, lags = c(1, 12),
                                 orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_ces_2013 <- auto.ces(cac40_train_2013)

# Prévision sur 12 mois
prev_adam_2014 <- forecast(fit_adam_2013, h = 12)
prev_adamarima_2014 <- forecast(fit_adamarima_2013, h = 12)
prev_arima_2014 <- forecast(fit_arima_2013, h = 12)
prev_hw_2014 <- forecast(fit_hw_2013, h = 12)
prev_ssarima_2014 <- forecast(fit_ssarima_2013, h = 12)
prev_ces_2014 <- forecast(fit_ces_2013, h = 12)

```

```{r}
# Créer l’axe des dates pour 2014
dates_2014 <- seq(as.Date("2014-01-01"), by = "month", length.out = 12)

# Regrouper toutes les prévisions
df_forecast_2014 <- tibble(
  Date = rep(dates_2014, times = 7),
  Valeur = c(as.numeric(prev_adam_2014$mean),
             as.numeric(prev_adamarima_2014$mean),
             as.numeric(prev_arima_2014$mean),
             as.numeric(prev_hw_2014$mean),
             as.numeric(prev_ssarima_2014$mean),
             as.numeric(prev_ces_2014$mean),
             as.numeric(cac40_test_2014)),
  Modèle = rep(c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES", "Réalisation"), each = 12)
)

# Tracer le graphique
ggplot(df_forecast_2014, aes(x = Date, y = Valeur, color = Modèle)) +
  geom_line(size = 1) +
  labs(
    title = "Prévisions sur l’année 2014 – comparaison des modèles",
    x = "Date",
    y = "Indice CAC 40"
  ) +
  theme_minimal(base_size = 13) +
  scale_color_manual(values = c(
    "ADAM.ETS" = "#E76F51",
    "ADAM.ETS.ARIMA" = "#9D4EDD",
    "ARIMA" = "#277DA1",
    "Holt-Winters" = "#2A9D8F",
    "SSARIMA" = "#F72585",
    "CES" = "#FFB703",
    "Réalisation" = "black"
  )) +
  theme(legend.title = element_blank())

```









# 5. Qualité de prévision 


## 5.1 -  MSE et R2oo

```{r}
# Créer la série d'apprentissage (jusqu’à fin 2017)
cac40_train <- window(cac40_ts, end = c(2017, 12))
cac40_test  <- window(cac40_ts, start = c(2018, 1), end = c(2018, 12))  # série "réalisée" en 2018

# Re-estimer les modèles
fit_adam <- auto.adam(cac40_train, model = "ZZZ", lags = c(1, 12), select = TRUE)
fit_adamarima <- auto.adam(cac40_train, model = "ZZZ", lags = c(1, 1, 12),
                           orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_arima <- auto.arima(cac40_train)
fit_hw <- HoltWinters(cac40_train, gamma = FALSE)
fit_ssarima <- auto.ssarima(cac40_train, lags = c(1, 12),
                            orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_ces <- auto.ces(cac40_train)

# Prévisions sur 12 mois (année 2018)
h <- 12
prev_adam       <- forecast(fit_adam, h = h)
prev_adamarima  <- forecast(fit_adamarima, h = h)
prev_arima      <- forecast(fit_arima, h = h)
prev_hw         <- forecast(fit_hw, h = h)
prev_ssarima    <- forecast(fit_ssarima, h = h)
prev_ces        <- forecast(fit_ces, h = h)

```

```{r}
# MSE
mse_adam      <- mean((cac40_test - prev_adam$mean)^2)
mse_adamarima <- mean((cac40_test - prev_adamarima$mean)^2)
mse_arima     <- mean((cac40_test - prev_arima$mean)^2)
mse_hw        <- mean((cac40_test - prev_hw$mean)^2)
mse_ssarima   <- mean((cac40_test - prev_ssarima$mean)^2)
mse_ces       <- mean((cac40_test - prev_ces$mean)^2)

# R² OOS
r2_adam       <- 1 - (mse_adam / mse_arima)
r2_adamarima  <- 1 - (mse_adamarima / mse_arima)
r2_hw         <- 1 - (mse_hw / mse_arima)
r2_ssarima    <- 1 - (mse_ssarima / mse_arima)
r2_ces        <- 1 - (mse_ces / mse_arima)

```


```{r}
tibble(
  Modèle       = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES"),
  MSE          = c(mse_adam, mse_adamarima, mse_arima, mse_hw, mse_ssarima, mse_ces),
  R2_OOS       = c(r2_adam, r2_adamarima, NA, r2_hw, r2_ssarima, r2_ces)
)
```

## 5.2 - Prédiction naïve

```{r}
# --- Prévision naïve : moyenne de la série d'apprentissage (benchmark alternatif) ---
naive_forecast <- mean(cac40_train)
mse_naive <- mean((cac40_test - naive_forecast)^2)

# --- R² OOS par rapport à la prévision naïve ---
r2_adam_naive       <- 1 - (mse_adam / mse_naive)
r2_adamarima_naive  <- 1 - (mse_adamarima / mse_naive)
r2_arima_naive      <- 1 - (mse_arima / mse_naive)
r2_hw_naive         <- 1 - (mse_hw / mse_naive)
r2_ssarima_naive    <- 1 - (mse_ssarima / mse_naive)
r2_ces_naive        <- 1 - (mse_ces / mse_naive)

# --- Tableau résumé avec comparaison au benchmark naïf ---
tibble(
  Modèle          = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES"),
  MSE             = c(mse_adam, mse_adamarima, mse_arima, mse_hw, mse_ssarima, mse_ces),
  R2_OOS_naive    = c(r2_adam_naive, r2_adamarima_naive, r2_arima_naive, r2_hw_naive, r2_ssarima_naive, r2_ces_naive)
)
mse_naive

mean(cac40_train)

```




## 5.3 -  Erreurs de prévision cumulées au carré (CSPE)

```{r}
library(tidyverse)

# Créer un tibble contenant les erreurs au carré par période
errors_cumul <- tibble(
  Mois = rep(1:12, times = 6),
  Erreur_carrée = c(
    (cac40_test - prev_adam$mean)^2,
    (cac40_test - prev_adamarima$mean)^2,
    (cac40_test - prev_arima$mean)^2,
    (cac40_test - prev_hw$mean)^2,
    (cac40_test - prev_ssarima$mean)^2,
    (cac40_test - prev_ces$mean)^2
  ),
  Modèle = rep(c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES"), each = 12)
)

# Calcul de l’erreur cumulée
errors_cumul <- errors_cumul %>%
  group_by(Modèle) %>%
  mutate(Erreur_cum = cumsum(Erreur_carrée))

# Graphique des erreurs cumulées
ggplot(errors_cumul, aes(x = Mois, y = Erreur_cum, color = Modèle)) +
  geom_line(size = 1.2) +
  labs(
    title = "Erreurs cumulées de prévision au carré (2018)",
    x = "Mois",
    y = "Erreur cumulée",
    color = "Modèle"
  ) +
  theme_minimal(base_size = 13)

```




# 6. Test de précision


```{r}
# Erreurs de prévision
err_adam       <- cac40_test - prev_adam$mean
err_adamarima  <- cac40_test - prev_adamarima$mean
err_arima      <- cac40_test - prev_arima$mean
err_hw         <- cac40_test - prev_hw$mean
err_ssarima    <- cac40_test - prev_ssarima$mean
err_ces        <- cac40_test - prev_ces$mean

# Prévision naïve : moyenne constante
naive_forecast <- ts(rep(mean(cac40_train), 12), start = c(2018, 1), frequency = 12)
err_naive      <- cac40_test - naive_forecast

```


```{r}
# Tests DM : modèle vs prévision naïve (h = 1 car horizon = 1 par point)
dm_adam <- dm.test(err_adam, err_naive, h = 1, alternative = "less")
dm_adamarima <- dm.test(err_adamarima, err_naive, h = 1, alternative = "less")
dm_arima <- dm.test(err_arima, err_naive, h = 1, alternative = "less")
dm_hw <- dm.test(err_hw, err_naive, h = 1, alternative = "less")
dm_ssarima <- dm.test(err_ssarima, err_naive, h = 1, alternative = "less")
dm_ces <- dm.test(err_ces, err_naive, h = 1, alternative = "less")

```



```{r}
library(tibble)

tibble(
  Modèle = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES"),
  p_value_DM_naive = c(
    dm_adam$p.value,
    dm_adamarima$p.value,
    dm_arima$p.value,
    dm_hw$p.value,
    dm_ssarima$p.value,
    dm_ces$p.value
  )
)

```


# 7. Prévision à 1 pas du meilleur modèle de la question 6

```{r}
# Prévision glissante sur l’année 2014 avec modèle ADAM ETS
# Année 2014
library(smooth)
library(tibble)

# Initialisation
h <- 1  # prévision à un mois
start_year <- 2014
start_month <- 1

# Vecteurs pour stocker les résultats
preds_adam <- numeric(12)
real_2014 <- numeric(12)

for (i in 0:11) {
  # Définir la fin de la fenêtre d'apprentissage
  train_end <- c(start_year, start_month + i - 1)
  
  # Extraire les données d'entraînement et la vraie valeur du mois à prévoir
  train_window <- window(cac40_ts, end = train_end)
  test_value <- window(cac40_ts, start = c(start_year, start_month + i), end = c(start_year, start_month + i))
  
  # Estimer le modèle ADAM.ETS sur la fenêtre glissante
  model_adam <- auto.adam(train_window, model = "ZZZ", lags = c(1, 12), select = TRUE)
  forecast_adam <- forecast(model_adam, h = h)
  
  # Stocker la prévision et la valeur réelle
  preds_adam[i + 1] <- forecast_adam$mean[1]
  real_2014[i + 1] <- as.numeric(test_value)
}

# Créer le tableau de résultats
df_glissant_adam <- tibble(
  Mois = 1:12,
  Réalisé = real_2014,
  Prévu = preds_adam,
  Erreur = real_2014 - preds_adam,
  Erreur2 = (real_2014 - preds_adam)^2
)

# Affichage du tableau
df_glissant_adam

```


```{r}
# Pour 2019

library(smooth)
library(tibble)

# Initialisation
h <- 1  # prévision à un mois
start_year <- 2019
start_month <- 1

# Vecteurs pour stocker les résultats
preds_adam <- numeric(12)
real_2019 <- numeric(12)

for (i in 0:11) {
  # Définir la fin de la fenêtre d'apprentissage (mois précédent)
  train_end <- c(start_year, start_month + i - 1)
  
  # Extraire la série d’apprentissage glissante et la vraie valeur suivante
  train_window <- window(cac40_ts, end = train_end)
  test_value <- window(cac40_ts, start = c(start_year, start_month + i), end = c(start_year, start_month + i))
  
  # Estimation du modèle ADAM ETS
  model_adam <- auto.adam(train_window, model = "ZZZ", lags = c(1, 12), select = TRUE)
  forecast_adam <- forecast(model_adam, h = h)
  
  # Stocker la prévision et la valeur observée
  preds_adam[i + 1] <- forecast_adam$mean[1]
  real_2019[i + 1] <- as.numeric(test_value)
}

# Création du tableau de résultats
df_glissant_adam <- tibble(
  Mois = 1:12,
  Réalisé = real_2019,
  Prévu = preds_adam,
  Erreur = real_2019 - preds_adam,
  Erreur2 = (real_2019 - preds_adam)^2
)

# Affichage
df_glissant_adam

```

