---
title: "Dossier"
author: "Pierre et Florian"
format:
  html:
    toc: true
    toc-title: Sommaire
    code-fold: true
    echo: true
    eval: true
    incremental: true
  pdf:
    toc: true
    toc-title: Sommaire
    echo: true
    eval: true
  revealjs:
    incremental: true
---

Choix 2 : Série CVS ou non saisonnière mensuelle

```{r}
# Importation des librairies

library(tidyquant)
library(tidyverse)
library(forecast)
library(RJDemetra)
library(tseries)
library(urca)
library(smooth)
```


# 1. Analyse préliminaire

## a. Présentation et caractérisation de la série étudiée : source, définition, graphique

```{r}
# Importation des données pour l'estimation

cac40 <- tq_get(
  "^FCHI",
  from = "2000-01-01", to = "2018-12-31", periodicity = "monthly"
) |>
  mutate(
    date = date %m+% months(1)
  ) |>
  select(
    date, close
  ) |>
  rename(
    cloture = close
  )

head(cac40, n = 20)
```

```{r}
# Importation des données pour la prévision

cac40_prev <- tq_get(
  "^FCHI",
  from = "2019-01-01", to = "2019-12-31", periodicity = "monthly"
) |>
  mutate(
    date = date %m+% months(1)
  ) |>
  select(
    date, close
  ) |>
  rename(
    cloture = close
  )

head(cac40, n = 20)
```

La série de données utilisée dans cette analyse provient du site Yahoo Finance (https://finance.yahoo.com/), une plateforme de référence pour les données financières et boursières.

Elle concerne l’indice CAC 40, qui regroupe les 40 plus grandes entreprises françaises cotées à la Bourse de Paris. Cet indice est un indicateur clé de la performance des marchés financiers en France.

La série temporelle mensuelle commence en janvier 2000 et se termine en décembre 2019, couvrant ainsi une période de 20 ans.


```{r}
# Classe time series

cac40_ts <- ts(
  data = cac40$cloture, 
  start = c(2000, 01), 
  frequency = 12
)

cac40_prev_ts <- ts(
  data = cac40_prev$cloture, 
  start = c(2019, 01), 
  frequency = 12
)

plot.ts(cac40_ts)
plot.ts(cac40_prev_ts)
```




## b. Détection des points atypiques, détermination du caractère multiplicatif ou additif du schéma et vérification de la saisonnalité

```{r}
# Méthode X13

regx13_1 <- regarima_x13(
  cac40_ts, 
  spec = "RG5c"
)
summary(regx13_1)

s_transform(regx13_1)
# plot(regx13_1)
```

Le modèle RegARIMA-X13 appliqué à la série cac40_ts repose sur une spécification ARIMA(0,1,1). Cela signifie que la série a été différenciée une fois pour atteindre la stationnarité, et que la dépendance résiduelle est modélisée à l’aide d’un terme de moyenne mobile d’ordre un. Cette structure est adaptée aux séries financières, où les variations mensuelles sont souvent plus stationnaires que les niveaux. Une transformation logarithmique a également été appliquée afin de stabiliser la variance de la série, souvent hétéroscédastique dans le cas d’indices boursiers.

Le modèle est estimé sur la période allant de janvier 2000 à décembre 2018. Les résultats montrent que le paramètre Theta(1) est estimé à 0.14893, avec une erreur standard de 0.06566. Ce paramètre est statistiquement significatif au seuil de 5 %, comme l’indique une p-value de 0.0243. La significativité de ce terme suggère que les chocs passés ont un effet direct sur l’évolution présente de la série, ce qui est cohérent avec le comportement souvent persistant des rendements boursiers.

Le modèle inclut un seul événement exceptionnel : un outlier de type additif (AO) en septembre 2002. Son coefficient, estimé à -0.15439 avec un t-stat de -4.925, est hautement significatif. Ce type de rupture représente une variation brutale et ponctuelle du niveau de la série, sans effet persistant au-delà de la période concernée. Une telle chute peut correspondre à un événement économique ou financier isolé ayant fortement influencé le marché ce mois-là.

Le modèle ne retient ni effet de calendrier (pas de jours ouvrables, pas d’effet Pâques ni d’année bissextile), ni constante. L’absence d’effets calendaires implique que la dynamique de la série ne semble pas influencée de manière systématique par ces composantes, du moins sur la période étudiée. Cela peut s’expliquer par la nature des données financières, où les effets saisonniers sont moins marqués qu’en démographie ou dans les ventes de détail.

Enfin, l’ajustement du modèle est satisfaisant, comme en témoigne l’erreur standard des résidus de 0.04784 et les 224 degrés de liberté. Les critères d’information sont cohérents avec une modélisation parcimonieuse : l’AIC est de 3068, l’AIC corrigé identique, et le BIC corrigé pour la longueur est de -6.032. Ce BIC légèrement négatif peut être interprété comme le résultat d’une vraisemblance relativement élevée combinée à une pénalisation plus forte sur le nombre de paramètres et la taille de l’échantillon. La comparaison des transformations montre que le modèle avec transformation logarithmique est préféré à celui sans transformation, le critère AIC ayant été amélioré de deux points. Cela confirme la pertinence de la transformation log pour améliorer la qualité de l’ajustement.


```{r}
# série ajustée du point atypique

ajustement <- regx13_1[["model"]][["effects"]]
log_cac40_ts <- ajustement[, "y_lin"]
log_cac40_prev_ts <- log(cac40_prev_ts)
```

```{r}
# Méthode X13

regx13_2 <- regarima_x13(
  log_cac40_ts, 
  spec = "RG5c"
)
summary(regx13_2)

s_transform(regx13_2)
# plot(regx13_2)
```

Plus de point atypique

# --------------------------------

```{r}
specification_1 <- regarima_spec_x13(
  spec = "RG5c",
  outlier.usedefcv = FALSE, 
  outlier.cv = 2.576 # seuil de significativité de 1 %
)

regx13_1 <- summary(regarima(cac40_ts, spec = specification_1))
regx13_1
```

```{r}
# Points atypiques significatifs à 0,1 %

outliers <- as_tibble(
  regx13_1[["coefficients"]][["regression"]], 
  rownames = "outliers") |> 
  filter(`Pr(>|t|)` < 0.001)

outliers
```

```{r}
# Extraction des types de points atypiques et des dates
outliers <- outliers |>
  mutate(
    points_atypiques = str_extract(outliers, "^[A-Za-z]+"),
    dates = str_extract(outliers, "\\d{1,2}-\\d{4}") |> 
      my() |> 
      format("%Y-%m")
  )

# Récupération des dates exactes
outliers$cac40_dates <- str_subset(
  cac40$date, 
  paste(outliers$dates, collapse = "|")
)

outliers
```

```{r}
specification_2 <- regarima_spec_x13(
  spec = "RG5c",
  usrdef.outliersEnabled = TRUE,
  usrdef.outliersType = outliers$points_atypiques,
  usrdef.outliersDate = outliers$cac40_dates
)

regx13_2 <- summary(regarima(cac40_ts, spec = specification_2))
regx13_2
```






### 3. Saisonnalité

```{r}
# Seasonal dummies
library(TSA)
library(seastests)
sd <- seasdum(log_cac40_ts)
show(sd)
```

Le test des variables muettes saisonnières (seasdum) a été appliqué à la série temporelle log_cac40_ts afin de détecter la présence d’une composante saisonnière. La statistique de test obtenue est de 0,98, avec une p-value associée de 0,4649234. Cette p-value étant supérieure aux seuils usuels de signification (5 % ou même 10 %), on ne rejette pas l’hypothèse nulle d’absence de saisonnalité. Cela signifie qu’il n’existe pas de preuve statistique suffisante pour affirmer que la série CAC 40 présente une variation régulière et récurrente selon les périodes (mois, trimestres, etc.).


```{r}
# Webel-Ollech test
wot <- combined_test(log_cac40_ts)
show(wot)
```

Le test combiné de type WO (Webel-Ollech) a été réalisé sur la série log_cac40_ts afin de détecter d’éventuels effets saisonniers ou calendaires. La statistique de test obtenue est 0, ce qui indique l'absence d’effet saisonnier détecté par le test. Les p-values associées aux différents sous-tests (1, 1, et 0.538) sont toutes bien supérieures au seuil classique de 5 %, ce qui signifie que l’on ne rejette pas l’hypothèse nulle d’absence de saisonnalité. En conclusion, le test ne met pas en évidence de structure saisonnière ou calendaire significative dans la série analysée.




## c. Vérifier la stationnarité de la série I(0) ou I(1)

### 1. Tests

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  log_cac40_ts,
  type = "drift",
  selectlags = "AIC"
)
summary(adf_test)
```

Le test de Dickey-Fuller Augmenté (ADF) a été appliqué à la série logarithmique du CAC40 pour évaluer la présence d’une racine unitaire, indicatrice de non-stationnarité. La statistique de test obtenue est de -2.3866, tandis que les valeurs critiques aux seuils de 1%, 5% et 10% sont respectivement -3.46, -2.88 et -2.57. Étant donné que la statistique est supérieure à ces seuils, nous ne pouvons pas rejeter l’hypothèse nulle de non-stationnarité. Ce résultat suggère donc que la série n’est pas stationnaire selon ce test.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  log_cac40_ts,
  type = "Z-tau",
  model = "constant",
  lags = "long"
)
summary(pp_test)
```

Le test de Phillips-Perron (PP), qui vise également à détecter une racine unitaire tout en étant plus robuste à l’hétéroscédasticité, a fourni une statistique de test Z-tau de -2.3959. Cette valeur reste supérieure aux valeurs critiques à 1%, 5% et 10%, qui sont respectivement -3.4606, -2.8744 et -2.5736. Ainsi, l’hypothèse nulle de racine unitaire n’est pas rejetée, ce qui confirme le résultat du test ADF et indique également une non-stationnarité de la série.


#### 3. Test de KPSS

```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  log_cac40_ts,
  type = "mu",
  lags = "long"
)
summary(kpss_test)
```

Le test KPSS fonctionne à l’inverse des deux précédents en testant l’hypothèse nulle de stationnarité. Pour notre série, la statistique de test est de 0.1374, nettement inférieure aux valeurs critiques à 10%, 5%, 2.5% et 1% (0.347, 0.463, 0.574 et 0.739 respectivement). Dans ce cas, on ne rejette pas l’hypothèse nulle de stationnarité, ce qui contraste avec les conclusions des tests ADF et PP.


#### 4. Conclusion

Les résultats des tests unitaires sont contradictoires. Alors que les tests ADF et PP ne rejettent pas l’hypothèse de non-stationnarité, le test KPSS n’invalide pas l’hypothèse de stationnarité. Cette divergence peut être le signe que la série est proche d’un comportement de racine unitaire ou que certains effets limites (comme un bruit élevé ou un choix de modèle inadapté) faussent les résultats. Face à cette divergence, il est pertinent de différencier la série et de réévaluer sa stationnarité.


### 2. Différenciation de la série

```{r}
# 1. Différencier la série
diff_log_cac40_ts <- diff(log_cac40_ts)
ts.plot(diff_log_cac40_ts)
```

Afin de corriger la non-stationnarité détectée par les tests ADF et PP, nous avons appliqué une différenciation première à la série logarithmique du CAC40. Cette transformation permet de stabiliser la moyenne de la série et d’atténuer les effets de tendance.


### 3. Tester la stationnarité après différenciation

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  diff_log_cac40_ts,
  type = "none",
  selectlags = "AIC"
)
summary(adf_test)
```

Après différenciation, la statistique de test ADF est de -10.524, ce qui est largement inférieur aux valeurs critiques à 1%, 5% et 10% (-2.58, -1.95, -1.62). Ce résultat très significatif nous permet de rejeter fermement l’hypothèse nulle de non-stationnarité. Ainsi, la série différenciée est stationnaire selon le test ADF.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  diff_log_cac40_ts,
  type = "Z-tau",
  model = "constant",
  lags = "short"
)
summary(pp_test)
```

Le test PP appliqué à la série différenciée donne une statistique Z-tau de -13.2906, une valeur également très inférieure aux seuils critiques de -3.4607, -2.8744 et -2.5736. Cela confirme que l’hypothèse de racine unitaire est nettement rejetée, et que la stationnarité est bien atteinte après transformation.


#### 3. Test de KPSS

```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  diff_log_cac40_ts,
  type = "mu"
)
summary(kpss_test)
```

Le test KPSS retourne une statistique de 0.1209, largement en dessous des seuils critiques à 10%, 5%, 2.5% et 1% (0.347, 0.463, 0.574, 0.739). On ne rejette donc pas l’hypothèse de stationnarité, ce qui vient confirmer les résultats des tests ADF et PP.


#### 4. Conclusion

Les trois tests convergent désormais vers une même conclusion : la série devient stationnaire après différenciation. Les tests ADF et PP rejettent l’hypothèse de racine unitaire, tandis que le test KPSS valide la stationnarité. Par conséquent, la transformation appliquée permet de rendre la série adaptée à des analyses économétriques plus avancées.


### 4. Corrélogrammes

```{r}
library(gridExtra)

# Corrélogramme

acf_graph1 <- log_cac40_ts |>
  ggAcf() +
  ggtitle("Corrélogramme sur la série en niveau") +
  theme_bw()

acf_graph2 <- diff_log_cac40_ts |>
  ggAcf() +
  ggtitle("Corrélogramme sur la série en différence première") +
  theme_bw()

grid.arrange(acf_graph1, acf_graph2, ncol = 2)
```

Avant la différenciation, la série, non stationnaire (comme une série intégrée I(1)), présente une autocorrélation significative sur les premiers retards, ce qui suggère la présence d'une racine unitaire et l'absence de stationnarité. Après la différenciation, l'ACF montre une légère autocorrélation au quatrième retard, avec des autocorrélations non significatives pour les autres retards, ce qui indique que la série est devenue stationnaire (I(0)). Ainsi, l'ACF de la série différenciée ne présente plus d'autocorrélations significatives, à l'exception d'une autocorrélation résiduelle éventuelle au quatrième retard, suggérant que la différenciation a éliminé la non-stationnarité, rendant la série adaptée à des analyses économétriques.




## d. Statistiques descriptives (moyenne, écart-type, skewness, kurtosis normalité, box-plot …). (cf. Chapitre 3 p38) Commenter

### 1. Statistiques

```{r}
library(fBasics)

stats <- basicStats(log_cac40_ts)
show(stats)
```


### 2. Normalité

```{r}
shapiro.test(log_cac40_ts)
```

La p-value de 0.01201, inférieure au seuil de 5 %, indique que l'hypothèse nulle de normalité est rejetée au seuil de risque de 5 %. Cela signifie que les données ne suivent pas une distribution normale. Ainsi, la série différenciée du CAC 40 n'est pas normalement distribuée d'après le test de Shapiro-Wilk.


### 3. Boîte à moustache

```{r}
boxplot(
  log_cac40_ts,
  main = "Boîte à moustaches de la série",
  ylab = "Valeurs",
  col = "lightblue"
)
```

```{r}
log_cac40_ts |>
  as.numeric() |>
  tibble(valeurs = _) |>
  ggplot(aes(x = valeurs, y = "")) +
  geom_violin(fill = "white", color = "black") +
  geom_boxplot(
    width = 0.5, fill = "grey", outlier.color = "red",
    outlier.size = 2, staplewidth = 0.4
  ) +
  labs(
    title = "Visualisation de la distribution des valeurs de log(CAC 40)",
    x = "Valeurs",
    y = "Distribution"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    axis.title.y = element_text(size = 14),
    axis.title.x = element_text(size = 14),
    axis.text.x = element_text(size = 12)
  )
```





# 2. Estimation des modèles linéaires de janvier 2000 à décembre 2018

a. Estimer et commenter les paramètres des modèles AR(1), AR(p) et ARIMA(p,d,q) et de la méthode LED Holt-Winters, ADAM ETS, ADAM ETS ARIMA, SSARIMA et CES 
b. Paramètres : présenter sous forme de tableau les paramètres des modèles précédents. Déterminer et commenter le meilleur modèle d’après les critères AIC et AICc 

```{r}
# Fonction pour afficher 4 graphiques

plot4 <- function(modele) {
  par(mfrow = c(2, 2))
  plot(modele)
  par(mfrow = c(1, 1))
}
```

## 2.1. Modèle ARIMA

### 2.1.1. Estimation du modèle

```{r}
modele_arima <- auto.arima(log_cac40_ts)

summary(modele_arima)

j <- ncol(modele_arima$var.coef)
tstat <- matrix(nrow=j, ncol=1)
for(i in 1:j)
{
  tstat[i,1] <- modele_arima$coef[i]/sqrt(modele_arima$var.coef[i,i])
}
tstat

# Graphique des valeurs ajustées
plot(modele_arima$fitted)
```




## 2.2. Méthode du lissage Exponentiel Double (LED) de Holt-Winters

### 2.2.1. Estimation du modèle

```{r}
modele_hw <- HoltWinters(
  log_cac40_ts, 
  gamma = FALSE
) # LED : niveau + tendance (sans saisonnalité)

summary(modele_hw)

# Graphique de la série et des valeurs ajustées
plot(modele_hw)

# Graphique des valeurs ajustées
plot(modele_hw$fitted[,1])
```



### 2.2.2. AIC et AICc

```{r}
# Nombre d'observations
n <- length(modele_hw$fitted[,1])

# Somme des carrés des résidus
RSS <- sum(residuals(modele_hw)^2)

# Nombre de paramètres estimés
k <- 2

# AIC manuel
aic_hw <- n * log(RSS / n) + 2 * k

# AICc manuel
aicc_hw <- aic_hw + (2 * k * (k + 1)) / (n - k - 1)

cat("AIC du modèle Holt-Winters :", round(aic_hw, 2), "\n")
cat("AICc du modèle Holt-Winters :", round(aicc_hw, 2), "\n")
```




## 2.3. Modèle ADAM ETS (Error-Trend-Seasonal)

### 2.3.1. Estimation du modèle

```{r}
modele_adam_ets <- auto.adam(
  log_cac40_ts,              # série mensuelle CAC 40
  model = "ZZN",         # sélection automatique de la structure ETS
  lags = c(1, 12),       # court terme et saisonnalité mensuelle
  select = TRUE          # sélection selon l'AIC
)

summary(modele_adam_ets)

show(modele_adam_ets)

# Graphiques des résultats du modèles
plot4(modele_adam_ets)

# Graphique des valeurs ajustées
plot(modele_adam_ets$fitted)
```



### 2.3.2. AIC et AICc

```{r}
aic_adam_ets <- AIC(modele_adam_ets)
cat("AIC du modèle ADAM ETS :", round(aic_adam_ets, 2), "\n")

aicc_adam_ets <- AICc(modele_adam_ets)
cat("AICc du modèle ADAM ETS :", round(aicc_adam_ets, 2), "\n")
```




## 2.4. Modèle ADAM ETS-ARIMA (modèle hybride)

### 2.4.1. Estimation du modèle

```{r}
modele_adam_ets_arima <- auto.adam(
  log_cac40_ts,                     # CAC 40 en log-niveau
  model = "ZZN",                    # sélection automatique,
                                    # sans composante saisonnière dans la partie ETS
  lags = c(1, 1, 12),               # (1) niveau/tendance ETS,
                                    # (2) ARIMA non-saisonnier,
                                    # (3) ARIMA saisonnier (mensuel)
  orders = list(
    ar = c(3, 3),                   # ordre autorégressif maximum :
                                    # 3 pour la partie non saisonnière,
                                    # 3 pour la partie saisonnière
    i  = c(2),                      # différenciation d’ordre 2 maximum pour stationnariser la série
    ma = c(3, 3)                    # ordre de moyenne mobile maximum :
                                    # 3 pour la partie non saisonnière,
                                    # 3 pour la partie saisonnière
  ),
  select = TRUE                     # sélection automatique du meilleur sous-modèle (AICc/BIC)
)


summary(modele_adam_ets_arima)

show(modele_adam_ets_arima)

# Graphiques des résultats du modèles
plot4(modele_adam_ets_arima)

# Graphique des valeurs ajustées
plot(modele_adam_ets_arima$fitted)
```



### 2.4.2. AIC et AICc

```{r}
aic_adam_ets_arima <- AIC(modele_adam_ets_arima)
cat("AIC du modèle ADAM ETS+ARIMA :", round(aic_adam_ets_arima, 2), "\n")

aicc_adam_ets_arima <- AICc(modele_adam_ets_arima)
cat("AICc du modèle ADAM ETS+ARIMA :", round(aicc_adam_ets_arima, 2), "\n")
```




## 2.5. Modèle SSARIMA (State Space ARIMA)

### 2.5.1. Estimation du modèle

```{r}
modele_ssarima <- auto.ssarima(
  log_cac40_ts,                      # CAC 40 en log-niveau
  lags = c(1, 12),                   # (1) niveau/tendance pour SARIMA, (12) saisonnalité mensuelle
  orders = list(
    ar = c(3, 3),                    # (3) ordre maximum pour AR non saisonnier et saisonnier
    i = c(2),                        # (2) différenciation d'ordre 2 maximum pour stationnariser la série
    ma = c(3, 3)                     # (3) ordre maximum pour MA non saisonnier et saisonnier
  ),
  select = TRUE                       # sélection automatique du meilleur sous-modèle (AICc/BIC)
)

summary(modele_ssarima)

show(modele_ssarima)

# Graphiques des résultats du modèles
plot4(modele_ssarima)

# Graphique des valeurs ajustées
plot(modele_ssarima$fitted)
```





### 2.5.2. AIC et AICc

```{r}
aic_ssarima <- AIC(modele_ssarima)
cat("AIC du modèle SSARIMA :", round(aic_ssarima, 2), "\n")

aicc_ssarima <- AICc(modele_ssarima)
cat("AICc du modèle SSARIMA :", round(aicc_ssarima, 2), "\n")
```





# 3. Prévision linéaire sur l'année 2019

```{r}
# Prévision à 12 mois
h <- 12
```

## 3.1. Modèle ARIMA

```{r}
# Prévision du modèle ARIMA

# Prévision à 12 mois avec intervalle de confiance à 80 % et 95 %
prevision_arima <- forecast(modele_arima, h = h)

show(prevision_arima)

plot(prevision_arima)

# Informations sur le modèle ajusté
modele_prevision_arima <- prevision_arima$model
show(modele_prevision_arima)

# Prévision
prev_arima <- prevision_arima$mean
show(prev_arima)
```




## 3.2. Méthode du lissage Exponentiel Double (LED) de Holt-Winters

```{r}
# Prévision du modèle LED Holt-Winters

# Prévision à 12 mois avec intervalle de confiance à 80 % et 95 %
prevision_hw <- forecast(
  modele_hw, 
  h = h
)

show(prevision_hw)

plot(prevision_hw)

# Informations sur le modèle ajusté
modele_prevision_hw <- prevision_hw$model
show(modele_prevision_hw)

# Prévision
prev_hw <- prevision_hw$mean
show(prev_hw)
```




## 3.3. Modèle ADAM ETS (Error-Trend-Seasonal)

```{r}
# Prévision du modèle ADAM ETS

# Prévision à 12 mois avec intervalle de confiance à 90 %
prevision_adam_ets <- forecast(
  modele_adam_ets, 
  h = h, 
  level = 0.90
)

show(prevision_adam_ets)

plot(prevision_adam_ets)

# Informations sur le modèle ajusté
modele_prevision_adam_ets <- prevision_adam_ets$model
show(modele_prevision_adam_ets)

# Prévision
prev_adam_ets <- prevision_adam_ets$mean
show(prev_adam_ets)
```




## 3.4. Modèle ADAM ETS-ARIMA (modèle hybride)

```{r}
# Prévision du modèle ADAM ETS-ARIMA

# Prévision à 12 mois avec intervalle de confiance à 90 %
prevision_adam_ets_arima <- forecast(
  modele_adam_ets_arima, 
  h = h, 
  level = 0.90
)

show(prevision_adam_ets_arima)

plot(prevision_adam_ets_arima)

# Informations sur le modèle ajusté
modele_prevision_adam_ets_arima <- prevision_adam_ets_arima$model
show(modele_prevision_adam_ets_arima)

# Prévision
prev_adam_ets_arima <- prevision_adam_ets_arima$mean
show(prev_adam_ets_arima)
```




## 3.5. Modèle SSARIMA (State Space ARIMA)

```{r}
# Prévision du modèle SSARIMA

# Prévision à 12 mois avec intervalle de confiance à 90 %
prevision_ssarima <- forecast(modele_ssarima, h = h, level = 0.90)

show(prevision_ssarima)

plot(prevision_ssarima)

# Informations sur le modèle ajusté
modele_prevision_ssarima <- prevision_ssarima$model
show(modele_prevision_ssarima)

# Prévision
prev_ssarima <- prevision_ssarima$mean
show(prev_ssarima)
```




## 3.6. Résultats 

```{r}
# Prévisions et série réalisée

df_previsions_2019 <- tibble(
  Date = cac40_prev$date,
  ARIMA = as.numeric(prev_arima),
  Holt_Winters = as.numeric(prev_hw),
  ADAM_ETS = as.numeric(prev_adam_ets),
  ADAM_ETS_ARIMA = as.numeric(prev_adam_ets_arima),
  SSARIMA = as.numeric(prev_ssarima),
  Realisation = as.numeric(log_cac40_prev_ts)
)

df_previsions_2019

# View(df_previsions_2019)
```





# 4. Représentation graphique de l’évolution des prévisions des différents modèles

```{r}
# Vecteur couleurs
couleurs_valeurs <- c(
  "ARIMA" = "#277DA1",
  "ADAM_ETS" = "#E76F51",
  "ADAM_ETS_ARIMA" = "#9D4EDD",
  "Holt_Winters" = "#2A9D8F",
  "SSARIMA" = "#F72585",
  "Realisation" = "black"
)

# Graphique des prévisions comparées à la série réalisée
df_previsions_2019 |> 
  pivot_longer(
    cols = -Date, 
    names_to = "Valeurs", 
    values_to = "Prediction"
  ) |> 
  ggplot() +
  aes(
    x = Date, 
    y = Prediction, 
    color = Valeurs
  ) +
  geom_line(size = 1.2) +
  labs(
    x = "Date", 
    y = "Valeur prédite"
  ) +
  scale_color_manual(values = couleurs_valeurs) +
  theme_bw(base_size = 13) +
  theme(legend.title = element_blank())
```






# 5. Qualité de prévision 

## 5.1. Modèle naïf

```{r}
# Prévision naïve : dernière valeur de la série d'apprentissage (benchmark)

# Prévision à 12 mois avec intervalle de confiance à 80 % et 95 %
prevision_naive <- naive(log_cac40_ts, h = h)

show(prevision_naive)

plot(prevision_naive)

# Informations sur le modèle ajusté
modele_prevision_naive <- prevision_naive$model
show(modele_prevision_naive)

# Prévision
prev_naive <- prevision_naive$mean
show(prev_naive)
```




## 5.2 -  MSE et R2oo

```{r}
# MSE
df_mse <- tibble(
  Critere = "MSE",
  Naive = mean((log_cac40_prev_ts - prev_naive)^2),
  ARIMA = mean((log_cac40_prev_ts - prev_arima)^2),
  Holt_Winters = mean((log_cac40_prev_ts - prev_hw)^2),
  ADAM_ETS = mean((log_cac40_prev_ts - prev_adam_ets)^2),
  ADAM_ETS_ARIMA = mean((log_cac40_prev_ts - prev_adam_ets_arima)^2),
  SSARIMA = mean((log_cac40_prev_ts - prev_ssarima)^2)
)
df_mse


# R2 OOS par rapport à la prévision naïve
df_r2 <- tibble(
  Critere = "R2_OOS",
  ARIMA = 1 - (df_mse$ARIMA / df_mse$Naive),
  Holt_Winters = 1 - (df_mse$Holt_Winters / df_mse$Naive),
  ADAM_ETS = 1 - (df_mse$ADAM_ETS / df_mse$Naive),
  ADAM_ETS_ARIMA = 1 - (df_mse$ADAM_ETS_ARIMA / df_mse$Naive),
  SSARIMA = 1 - (df_mse$SSARIMA / df_mse$Naive)
)
df_r2

# Tableau récapitulatif des performances de prévision : MSE et R2 OOS
df_mse_r2 <- bind_rows(df_mse, df_r2)
df_mse_r2
```




## 5.3 -  Erreurs de prévision cumulées au carré (CSPE)

```{r}
library(tibble)

errors_cumul <- tibble(
  Mois = rep(1:12, times = 5),
  Erreur_carrée = c(
    (log_cac40_prev_ts- prev_adam$mean)^2,
    (log_cac40_prev_ts - prev_adamarima$mean)^2,
    (log_cac40_prev_ts - prev_arima$mean)^2,
    (log_cac40_prev_ts - prev_hw$mean)^2,
    (log_cac40_prev_ts - prev_ssarima$mean)^2
  ),
  Modèle = rep(c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA"), each = 12)
)


# Calcul de l’erreur cumulée
errors_cumul <- errors_cumul %>%
  group_by(Modèle) %>%
  mutate(Erreur_cum = cumsum(Erreur_carrée))

# Graphique des erreurs cumulées
ggplot(errors_cumul, aes(x = Mois, y = Erreur_cum, color = Modèle)) +
  geom_line(size = 1.2) +
  labs(
    x = "Mois",
    y = "Erreur cumulée",
    color = "Modèle"
  ) +
  theme_minimal(base_size = 13)

```





# 6. Test de précision


```{r}
# Erreurs de prévision
err_adam       <- log_cac40_prev_ts - prev_adam$mean
err_adamarima  <- log_cac40_prev_ts- prev_adamarima$mean
err_arima      <- log_cac40_prev_ts - prev_arima$mean
err_hw         <- log_cac40_prev_ts - prev_hw$mean
err_ssarima    <- log_cac40_prev_ts - prev_ssarima$mean

# Prévision naïve : moyenne constante
naive_forecast 
err_naive      <- log_cac40_prev_ts - naive_forecast

```


```{r}
# Tests DM : modèle vs prévision naïve (h = 1 car horizon = 1 par point)
dm_adam <- dm.test(err_adam, err_naive, h = 1, alternative = "less")
dm_adamarima <- dm.test(err_adamarima, err_naive, h = 1, alternative = "less")
dm_arima <- dm.test(err_arima, err_naive, h = 1, alternative = "less")
dm_hw <- dm.test(err_hw, err_naive, h = 1, alternative = "less")
dm_ssarima <- dm.test(err_ssarima, err_naive, h = 1, alternative = "less")
```



```{r}
library(tibble)

tibble(
  Modèle = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA"),
  p_value_DM_naive = c(
    dm_adam$p.value,
    dm_adamarima$p.value,
    dm_arima$p.value,
    dm_hw$p.value,
    dm_ssarima$p.value
  )
)

```





# 7. Prévision à 1 pas du meilleur modèle de la question 6

```{r}
# Initialisation
estimation <- log_cac40_ts

# Prévisions pour 12 périodes
prevision <- map_dbl(1:12, function(i) {
  
  # Ajout de la dernière valeur observée avant la prévision
  if (i > 1) {
    estimation <- ts(
      c(log_cac40_ts, log_cac40_prev_ts[1:(i - 1)]), 
      frequency = 12
    )
  }
  
  # Prévision à un pas
  forecast(
    auto.adam(
      estimation,
      model = "ZZN",
      lags = c(1, 12),
      orders = list(ar = c(3, 3), i = 2, ma = c(3, 3), select = TRUE)
    ), 
    h = 1, 
    level = 0.90
  )$mean[1]
})

prevision
```


```{r}
# Dataframe avec les dates, les prévisions du modèle et les réalisations

df <- tibble(
  Date = cac40_prev$date,
  Prévision = prevision,
  Réalisation = log(cac40_prev$cloture)
)


# Graphique

df |> 
  ggplot() +
  aes(x = Date) +
  geom_line(aes(y = Prévision, color = "Prévision"), size = 1) +
  geom_line(aes(y = Réalisation, color = "Réalisation"), size = 1) +
  labs(
    title = "Comparaison des prévisions et des réalisations",
    x = "Date",
    y = "Valeur",
    color = "Série"
  ) +
  scale_color_manual(values = c("Prévision" = "blue", "Réalisation" = "red")) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```
