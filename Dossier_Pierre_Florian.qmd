---
title: "Dossier"
author: "Pierre et Florian"
format:
  html:
    toc: true
    toc-title: Sommaire
    code-fold: true
    echo: true
    eval: true
    incremental: true
  pdf:
    toc: true
    toc-title: Sommaire
    echo: true
    eval: true
  revealjs:
    incremental: true
---

Choix 2 : Série CVS  ou non saisonnière mensuelle 
(Possibilité d’utiliser la série du dossier cours « Séries temporelles univariées »)  

```{r}
# Importation des librairies

library(tidyquant)
library(tidyverse)
library(forecast)
library(seastests)
```

# 1. Analyse préliminaire

## a. Présentation et caractérisation de la série étudiée : source, définition, graphique


### 1. Présentation

```{r}
# Importation des données

cac40 <- tq_get(
  "^FCHI",
  from = "2000-01-01", to = "2019-12-31", periodicity = "monthly"
) |>
  mutate(
    date = date %m+% months(1)
  ) |>
  select(
    date, close
  ) |>
  rename(
    cloture = close
  )

head(cac40, n = 20)
```


La série de données utilisée dans cette analyse provient du site Yahoo Finance (https://finance.yahoo.com/), une plateforme de référence pour les données financières et boursières.

Elle concerne l’indice CAC 40, qui regroupe les 40 plus grandes entreprises françaises cotées à la Bourse de Paris. Cet indice est un indicateur clé de la performance des marchés financiers en France.

La série temporelle mensuelle commence en janvier 2000 et se termine en décembre 2019, couvrant ainsi une période de 20 ans.


```{r}
# Classe time series
cac40_ts <- ts(data = cac40$cloture, start = c(2000, 01), frequency = 12)

plot.ts(cac40_ts)
```


### 2. Caractéristiques (saisonnalité ?)

```{r}
# Seasonal dummies
library(TSA)
sd <- seasdum(cac40_ts)
show(sd)
```

Le test des variables muettes saisonnières (seasdum) a été appliqué à la série temporelle cac40_ts afin de détecter la présence d’une composante saisonnière. La statistique de test obtenue est de 1,47, avec une p-value associée de 0,1445. Cette p-value étant supérieure aux seuils usuels de signification (5 % ou même 10 %), on ne rejette pas l’hypothèse nulle d’absence de saisonnalité. Cela signifie qu’il n’existe pas de preuve statistique suffisante pour affirmer que la série CAC 40 présente une variation régulière et récurrente selon les périodes (mois, trimestres, etc.).


```{r}
# Webel-Ollech test - new version of seastests (2021-09)
wot <- combined_test(cac40_ts)
show(wot)
```

Le test combiné de type WO (combined_test) a été réalisé pour détecter des effets saisonniers ou calendaire multiples dans la série cac40_ts. La statistique de test globale est de 0, avec des p-values respectives de 1, 1 et 0,1039 pour les différents sous-tests. La p-value finale étant légèrement supérieure à 10 %, on ne rejette pas non plus l’hypothèse nulle d’absence d’effet saisonnier ou calendaire. Ainsi, ce test ne met pas en évidence de structure saisonnière marquée ni d’effet lié à des facteurs calendaires dans la série analysée.


## b. Détection des points atypiques. Présenter ces points sous forme de tableau (date, type de point (AO, TC …), t-stat) et trouver des explications économiques de l’apparition des 3 plus importants 

```{r}
library(tsoutliers)

fit <- tso(cac40_ts)
plot(fit)
show(fit)
```

À l’indice 97, soit en janvier 2008, le modèle détecte un changement négatif de niveau (LS) important sur le CAC 40, de l’ordre de –726 points. Il s'agit d’un point atypique structurel dans la série.
Cette chute brutale de niveau subie par le CAC 40 en janvier 2008 correspond très probablement au début de la crise financière mondiale des subprimes. Le marché avait commencé à anticiper l'effondrement des banques, ce qui a provoqué une forte baisse des indices boursiers.


```{r}
# Série corrigée des points atypiques
cac40_ts <- fit$yadj
plot(cac40_ts)
```


## c. Vérifier la stationnarité de la série I(0) ou I(1)

### 1. Tests

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Chargement des bibliothèques nécessaires
library(tseries)
library(urca)

# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  cac40_ts, 
  type = "drift", 
  selectlags = "AIC"
)
summary(adf_test)
```


Le test de Dickey-Fuller augmentée (ADF) permet de tester l'hypothèse nulle selon laquelle la série temporelle possède une racine unitaire, ce qui indique une non-stationnarité. Dans les résultats, le test ADF fournit une statistique de test de -1.5354, qui est supérieure aux valeurs critiques à 1%, 5% et 10%. Cela indique que nous ne rejetons pas l'hypothèse nulle au seuil de 5%, ce qui suggère que la série temporelle présente une racine unitaire et n'est donc pas stationnaire. En outre, la p-value associée à l'estimation de la pente du modèle (0.126) confirme l'absence de significativité du test, renforçant ainsi l'idée de non-stationnarité.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  cac40_ts, 
  type = "Z-tau", 
  model = "constant", 
  lags = "short"
)
summary(pp_test)
```

Le test de Philips et Perron (PP) est également utilisé pour tester la présence d'une racine unitaire dans une série temporelle, mais il est moins sensible aux problèmes d'hétéroscédasticité. Dans ce cas, la statistique de test Z-tau est -1.4192, ce qui est également supérieur aux valeurs critiques à 1%, 5% et 10%. Cela indique, tout comme pour le test ADF, que nous ne rejetons pas l'hypothèse nulle et que la série temporelle n'est pas stationnaire. La p-value pour le coefficient de la variable retardée (0.000) est très significative, indiquant que la série temporelle suit un modèle autorégressif, mais cela ne suffit pas à conclure à la stationnarité.


```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  cac40_ts, 
  type = "mu"
)
summary(kpss_test)
```

#### 3. Test de KPSS

Le test de KPSS (Kwiatkowski-Phillips-Schmidt-Shin) teste l'hypothèse nulle selon laquelle la série est stationnaire. La statistique de test est de 1.2038, qui est bien au-dessus des valeurs critiques pour le niveau de signification de 1%, 5% et 10% (0.739, 0.463, 0.347 respectivement). Cela suggère que nous rejetons l'hypothèse nulle de stationnarité au seuil de 5%, ce qui appuie la conclusion que la série temporelle est non stationnaire. Cette conclusion est cohérente avec les résultats des tests ADF et PP.


#### 4. Conclusion

Les résultats des trois tests unitaires (ADF, PP, et KPSS) indiquent que la série temporelle étudiée, en l'occurrence le CAC40, n'est pas stationnaire. Le test ADF et le test PP, tous deux basés sur l'hypothèse de non-stationnarité, n'ont pas permis de rejeter cette hypothèse, et le test KPSS a montré des preuves contraires à la stationnarité. Ces tests convergent vers la même conclusion : la série présente probablement une racine unitaire, ce qui nécessite probablement une différenciation pour la rendre stationnaire avant d'effectuer toute modélisation.


### 2. Différenciation de la série

```{r}
# 1. Différencier la série
diff_cac40_ts <- diff(cac40_ts)
```


### 3. Tester la stationnarité après différenciation

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  diff_cac40_ts, 
  type = "drift", 
  selectlags = "AIC"
)
summary(adf_test)
```

Après différenciation de la série temporelle, le test de Dickey-Fuller augmentée (ADF) fournit une statistique de test de -11.2704. Cette valeur est largement inférieure aux valeurs critiques à 1%, 5%, et 10%, qui sont respectivement -3.46, -2.88 et -2.57. Par conséquent, nous rejetons l'hypothèse nulle de la présence d'une racine unitaire, ce qui indique que la série différenciée est stationnaire. De plus, la p-value associée au coefficient de la variable retardée (z.lag.1) est très significative (<2e-16), renforçant cette conclusion de stationnarité après différenciation.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  diff_cac40_ts, 
  type = "Z-tau", 
  model = "constant", 
  lags = "short"
)
summary(pp_test)
```

Le test de Philips et Perron (PP) sur la série différenciée fournit une statistique de test Z-tau de -14.733, qui est bien en dessous des valeurs critiques de -3.459, -2.874 et -2.573 pour les niveaux de signification respectifs de 1%, 5% et 10%. Cela conduit également au rejet de l'hypothèse nulle de la présence d'une racine unitaire. Cependant, la p-value pour le coefficient de la variable retardée (y.l1) est de 0.379, ce qui indique qu'il n'est pas significativement différent de zéro. Néanmoins, la statistique Z-tau suggère que la série est stationnaire après différenciation.


#### 3. Test de KPSS

```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  diff_cac40_ts, 
  type = "mu"
)
summary(kpss_test)
```

Le test de KPSS sur la série différenciée donne une statistique de test de 0.2108, bien inférieure aux valeurs critiques à 1%, 5%, 2.5%, et 10% (respectivement 0.739, 0.574, 0.463, et 0.347). Cela permet de ne pas rejeter l'hypothèse nulle de stationnarité au niveau de 5%. Le résultat du test KPSS confirme donc que la série différenciée est stationnaire.


#### 4. Conclusion

Les résultats des trois tests unitaires (ADF, PP et KPSS) sur la série temporelle différenciée indiquent que la différenciation a permis de rendre la série stationnaire. Le test ADF et le test PP rejettent l'hypothèse nulle de la présence d'une racine unitaire, et le test KPSS ne rejette pas l'hypothèse nulle de stationnarité. Ces résultats convergent vers la conclusion que la série différenciée est stationnaire, ce qui permet de procéder à des analyses et modélisations futures sur cette série.


### 4. Corrélogrammes

```{r}
library(gridExtra)

# Corrélogramme

acf_graph1 <- cac40_ts |> 
  ggAcf() +
  ggtitle("Corrélogramme sur la série en niveau") +
  theme_bw()

acf_graph2 <- diff_cac40_ts |>  
  ggAcf() +
  ggtitle("Corrélogramme sur la série en différence première") +
  theme_bw()

grid.arrange(acf_graph1, acf_graph2, ncol = 2)
```

Avant la différenciation, la série non stationnaire (comme une série intégrée I(1)) montre une autocorrélation significative sur les premiers lags, ce qui indique la présence d'une racine unitaire et l'absence de stationnarité. En revanche, après la différenciation, l'ACF se stabilise autour de zéro, avec des autocorrélations non significatives, ce qui suggère que la série est devenue stationnaire (I(0)). Ainsi, l'ACF de la série différenciée ne montre plus d'autocorrélations significatives, confirmant que la différenciation a éliminé la non-stationnarité, rendant la série adaptée à des analyses économétriques.


## d. Statistiques descriptives (moyenne, écart-type, skewness, kurtosis normalité, box-plot …). (cf. Chapitre 3 p38) Commenter

```{r}
library(fBasics)

stats <- basicStats(diff_cac40_ts)
show(stats)
```


La série différenciée du CAC 40 présente un minimum de -744,29, qui correspond à janvier 2008, ce qui reflète une chute importante de l'indice à cette période, probablement en raison de la crise financière mondiale déclenchée par la crise des subprimes, entraînant une baisse significative de l'indice.

Le maximum de 531,15 représente une hausse notable de l'indice, mais cette variation positive reste inférieure à la baisse maximale.

La moyenne de 1,35 indique que, en moyenne, les variations journalières de l'indice sont légèrement positives. Cependant, cette moyenne est faible, suggérant des fluctuations modérées au quotidien.

La médiane est de 38,08, ce qui montre qu'une proportion significative des observations diffère considérablement de la moyenne. En d'autres termes, la série n'est pas symétrique et présente une certaine asymétrie dans les variations de l'indice, avec des valeurs qui peuvent s'écarter de la moyenne de manière plus prononcée.

L'écart-type de 211,13 reflète la volatilité relativement élevée de la série. Les variations journalières du CAC 40 s'écartent de la moyenne de manière substantielle, ce qui indique une instabilité dans les mouvements de l'indice et des fluctuations importantes dans ses valeurs.

La skewness de -0,66 suggère que la distribution de la série est légèrement asymétrique à gauche. Cela signifie qu'il y a une prédisposition pour les baisses de l'indice à être plus marquées que les hausses, créant une queue plus longue du côté négatif de la distribution.

Enfin, la kurtosis de 0,71 est inférieure à 3, ce qui indique que la distribution des variations est moins pointue que celle d'une distribution normale. Il y a donc moins de valeurs extrêmes dans la série, ce qui suggère que les mouvements extrêmes du CAC 40 sont relativement rares par rapport à une distribution normale.


```{r}
# ATTENTION : hypothèses à vérifier avant d'utiliser ce test
shapiro.test(diff_cac40_ts)
```

La p-value de 0.0001398, inférieure à 0.01, indique que l'hypothèse nulle est rejetée au seuil de risque de 1%. Cela signifie que les données ne suivent pas une distribution normale. Ainsi, la série différenciée du CAC 40 n'est pas normalement distribuée d'après le test de Shapiro-Wilk.

```{r}
boxplot(
  diff_cac40_ts,
  main = "Boxplot de la série diff_cac40",
  ylab = "Différenciation du CAC40"
)
```

Nous observons plusieurs valeurs potentiellement atypiques.
Nous devons vérifier si ces valeurs sont réellement atypiques.


```{r}
library(EnvStats)
rosnerTest(diff_cac40_ts, k = 10, alpha = 0.05)
```

D'après le test de Rosner, ces valeurs ne sont pas considérées comme atypiques.




# 2. Estimation des modèles linéaires  
## a. Estimer et commenter les paramètres des modèles AR(1), AR(p) et ARIMA(p,d,q) et de 
la méthode LED Holt-Winters, ADAM ETS, ADAM ETS ARIMA, SSARIMA et CES 

# POSER AU PROF LA QUESTION : devons-nous utiliser les séries différenciées en fonction du modèle ?

### AR(1)
```{r}
library(forecast)
mod_ar1 <- Arima(diff_cac40_ts, order = c(1, 0, 0))
summary(mod_ar1)
```


### AR(p)

```{r}
mod_arp <- ar(diff_cac40_ts, aic=TRUE, order.max=12)
mod_arp$order
mod_arp$ar
```



### Autoarima

```{r}
mod_arima <- auto.arima(cac40_ts)
summary(mod_arima)
```


### Lissage Exponentiel Double (LED) de Holt-Winters

```{r}
# ---- Modélisation ----

# Modèle LED Holt-Winters : lissage exponentiel double (niveau + tendance)
m <- HoltWinters(cac40_ts, gamma = FALSE)

# ---- prévision ----

# Prévision sur un horizon h = 50 avec intervalles de confiance à 80% et 95%
fit <- forecast(m, h = 50) # ← prévision à 50 périodes
plot(fit)
show(fit)

# Prévisions ponctuelles
prevf <- fit$mean # ← point de prévision
show(prevf)

# Informations sur le modèle ajusté
mod <- fit$model
show(mod)
```


###  ADAM ETS (Error-Trend-Seasonal)

```{r}
# Chargement de la librairie
library(smooth)

# Estimation du modèle ADAM ETS (ZZZ = sélection automatique)
fit_adam_ets <- auto.adam(
  cac40_ts,              # série mensuelle CAC 40
  model = "ZZZ",         # sélection automatique de la structure ETS
  lags = c(1, 12),       # court terme et saisonnalité mensuelle
  select = TRUE          # sélection selon l'AIC
)

# Prévision à 12 mois avec intervalle de confiance à 90 %
prev_adam_ets <- forecast(fit_adam_ets, h = 12, level = 0.90)

# Affichage des prévisions
plot(prev_adam_ets)

# Aperçu des valeurs prédites
prev_adam_ets

```


### ADAM ETS-ARIMA (modèle hybride)

```{r}
# Modèle ADAM ETS + ARIMA
library(smooth)

fit_adam_ets_arima <- auto.adam(
  cac40_ts,                          # série CAC 40 en niveau
  model = "ZZZ",                     # sélection automatique ETS
  lags = c(1, 1, 12),                # lags pour tendance, ARIMA, saisonnalité
  orders = list(
    ar = c(3, 3),                    # ordres AR non saisonnier / saisonnier
    i  = c(2),                       # ordre de différenciation
    ma = c(3, 3)                     # ordres MA non saisonnier / saisonnier
  ),
  select = TRUE                     # sélection automatique du meilleur sous-modèle
)

# Prévision sur 12 mois avec IC à 90 %
prev_adam_ets_arima <- forecast(fit_adam_ets_arima, h = 12, level = 0.90)

# Affichage des prévisions
prev_adam_ets_arima
plot(prev_adam_ets_arima)

```


### SSARIMA (State Space ARIMA)

```{r}
# Modèle SSARIMA
library(smooth)

fitssarima <- auto.ssarima(
  cac40_ts, # série utilisée
  lags = c(1, 12), # spécifie une structure SARIMA mensuelle
  orders = list(
    ar = c(3, 3), # ordre max AR non saisonnier et saisonnier
    i = c(2), # ordre max de différenciation
    ma = c(3, 3)
  ), # ordre max MA non saisonnier et saisonnier
  select = TRUE # sélection automatique du meilleur modèle
)

summary(fitssarima)

# Graphiques
par(mfcol = c(2, 2))
plot(fitssarima)

# Prévision sur 12 mois (avec IC à 90 %)
prevssarima <- forecast(fitssarima, h = 12, level = 0.90) # ← prévision du modèle SSARIMA pour h = 12
plot(prevssarima)
```

### CES (Complex Exponential Smoothing)

```{r}
# Modèle CES (Complex Exponential Smoothing)
library(smooth)

# Estimation automatique du meilleur modèle CES
mod_ces <- auto.ces(
  cac40_ts, # série temporelle utilisée
)

# Résumé des paramètres estimés, AIC, erreurs, etc.
summary(mod_ces)

# Graphiques de diagnostic (décomposition, résidus, QQ-plot, etc.)
par(mfrow = c(2, 2)) # disposition des 4 graphiques
plot(mod_ces)

# Prévision sur 12 périodes avec intervalle à 95 %
prev_ces <- forecast(mod_ces, h = 12, level = 0.95)

# Graphique des prévisions avec intervalle de confiance
plot(prev_ces)
```







# 3. Prévision linéaire sur une année 




# 5. Qualité de prévision 


## 5.1 MSE et R2oo

```{r}
# Créer la série d'apprentissage (jusqu’à fin 2017)
cac40_train <- window(cac40_ts, end = c(2017, 12))
cac40_test  <- window(cac40_ts, start = c(2018, 1), end = c(2018, 12))  # série "réalisée" en 2018

# Re-estimer les modèles
fit_adam <- auto.adam(cac40_train, model = "ZZZ", lags = c(1, 12), select = TRUE)
fit_adamarima <- auto.adam(cac40_train, model = "ZZZ", lags = c(1, 1, 12),
                           orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_arima <- auto.arima(cac40_train)
fit_hw <- HoltWinters(cac40_train, gamma = FALSE)
fit_ssarima <- auto.ssarima(cac40_train, lags = c(1, 12),
                            orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_ces <- auto.ces(cac40_train)

# Prévisions sur 12 mois (année 2018)
h <- 12
prev_adam       <- forecast(fit_adam, h = h)
prev_adamarima  <- forecast(fit_adamarima, h = h)
prev_arima      <- forecast(fit_arima, h = h)
prev_hw         <- forecast(fit_hw, h = h)
prev_ssarima    <- forecast(fit_ssarima, h = h)
prev_ces        <- forecast(fit_ces, h = h)

```



```{r}
# MSE
mse_adam      <- mean((cac40_test - prev_adam$mean)^2)
mse_adamarima <- mean((cac40_test - prev_adamarima$mean)^2)
mse_arima     <- mean((cac40_test - prev_arima$mean)^2)
mse_hw        <- mean((cac40_test - prev_hw$mean)^2)
mse_ssarima   <- mean((cac40_test - prev_ssarima$mean)^2)
mse_ces       <- mean((cac40_test - prev_ces$mean)^2)

# R² OOS
r2_adam       <- 1 - (mse_adam / mse_arima)
r2_adamarima  <- 1 - (mse_adamarima / mse_arima)
r2_hw         <- 1 - (mse_hw / mse_arima)
r2_ssarima    <- 1 - (mse_ssarima / mse_arima)
r2_ces        <- 1 - (mse_ces / mse_arima)

```


```{r}
tibble(
  Modèle       = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES"),
  MSE          = c(mse_adam, mse_adamarima, mse_arima, mse_hw, mse_ssarima, mse_ces),
  R2_OOS       = c(r2_adam, r2_adamarima, NA, r2_hw, r2_ssarima, r2_ces)
)
```

### Prédiction naïve

```{r}
# --- Prévision naïve : moyenne de la série d'apprentissage (benchmark alternatif) ---
naive_forecast <- mean(cac40_train)
mse_naive <- mean((cac40_test - naive_forecast)^2)

# --- R² OOS par rapport à la prévision naïve ---
r2_adam_naive       <- 1 - (mse_adam / mse_naive)
r2_adamarima_naive  <- 1 - (mse_adamarima / mse_naive)
r2_arima_naive      <- 1 - (mse_arima / mse_naive)
r2_hw_naive         <- 1 - (mse_hw / mse_naive)
r2_ssarima_naive    <- 1 - (mse_ssarima / mse_naive)
r2_ces_naive        <- 1 - (mse_ces / mse_naive)

# --- Tableau résumé avec comparaison au benchmark naïf ---
tibble(
  Modèle          = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES"),
  MSE             = c(mse_adam, mse_adamarima, mse_arima, mse_hw, mse_ssarima, mse_ces),
  R2_OOS_naive    = c(r2_adam_naive, r2_adamarima_naive, r2_arima_naive, r2_hw_naive, r2_ssarima_naive, r2_ces_naive)
)
mse_naive

mean(cac40_train)

```




### Erreurs de prévision cumulées au carré (CSPE)

```{r}
library(tidyverse)

# Créer un tibble contenant les erreurs au carré par période
errors_cumul <- tibble(
  Mois = rep(1:12, times = 6),
  Erreur_carrée = c(
    (cac40_test - prev_adam$mean)^2,
    (cac40_test - prev_adamarima$mean)^2,
    (cac40_test - prev_arima$mean)^2,
    (cac40_test - prev_hw$mean)^2,
    (cac40_test - prev_ssarima$mean)^2,
    (cac40_test - prev_ces$mean)^2
  ),
  Modèle = rep(c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "CES"), each = 12)
)

# Calcul de l’erreur cumulée
errors_cumul <- errors_cumul %>%
  group_by(Modèle) %>%
  mutate(Erreur_cum = cumsum(Erreur_carrée))

# Graphique des erreurs cumulées
ggplot(errors_cumul, aes(x = Mois, y = Erreur_cum, color = Modèle)) +
  geom_line(size = 1.2) +
  labs(
    title = "Erreurs cumulées de prévision au carré (2018)",
    x = "Mois",
    y = "Erreur cumulée",
    color = "Modèle"
  ) +
  theme_minimal(base_size = 13)

```



