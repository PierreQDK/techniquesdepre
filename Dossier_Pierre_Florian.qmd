---
title: "Dossier"
author: "Pierre et Florian"
format:
  html:
    toc: true
    toc-title: Sommaire
    code-fold: true
    echo: true
    eval: true
    incremental: true
  pdf:
    toc: true
    toc-title: Sommaire
    echo: true
    eval: true
  revealjs:
    incremental: true
---

Choix 2 : Série CVS ou non saisonnière mensuelle

```{r}
# Importation des librairies

library(tidyquant)
library(tidyverse)
library(forecast)
library(RJDemetra)
library(tseries)
library(urca)
```


# 1. Analyse préliminaire

## a. Présentation et caractérisation de la série étudiée : source, définition, graphique

```{r}
# Importation des données pour l'estimation

cac40 <- tq_get(
  "^FCHI",
  from = "2000-01-01", to = "2018-12-31", periodicity = "monthly"
) |>
  mutate(
    date = date %m+% months(1)
  ) |>
  select(
    date, close
  ) |>
  rename(
    cloture = close
  )

head(cac40, n = 20)
```

```{r}
# Importation des données pour la prévision

cac40_prev <- tq_get(
  "^FCHI",
  from = "2019-01-01", to = "2019-12-31", periodicity = "monthly"
) |>
  mutate(
    date = date %m+% months(1)
  ) |>
  select(
    date, close
  ) |>
  rename(
    cloture = close
  )

head(cac40, n = 20)
```

La série de données utilisée dans cette analyse provient du site Yahoo Finance (https://finance.yahoo.com/), une plateforme de référence pour les données financières et boursières.

Elle concerne l’indice CAC 40, qui regroupe les 40 plus grandes entreprises françaises cotées à la Bourse de Paris. Cet indice est un indicateur clé de la performance des marchés financiers en France.

La série temporelle mensuelle commence en janvier 2000 et se termine en décembre 2019, couvrant ainsi une période de 20 ans.


```{r}
# Classe time series

cac40_ts <- ts(
  data = cac40$cloture, 
  start = c(2000, 01), 
  frequency = 12
)

cac40_prev_ts <- ts(
  data = cac40_prev$cloture, 
  start = c(2019, 01), 
  frequency = 12
)

plot.ts(cac40_ts)
plot.ts(cac40_prev_ts)
```



## b. Détection des points atypiques, détermination du caractère multiplicatif ou additif du schéma et vérification de la saisonnalité

```{r}
## X13 method
myregx13 <- regarima_x13(cac40_ts, spec = "RG5c")
summary(myregx13)
s_transform(myregx13)
# plot(myregx13)
```

Le modèle RegARIMA-X13 appliqué à la série cac40_ts repose sur une spécification ARIMA(0,1,1). Cela signifie que la série a été différenciée une fois pour atteindre la stationnarité, et que la dépendance résiduelle est modélisée à l’aide d’un terme de moyenne mobile d’ordre un. Cette structure est adaptée aux séries financières, où les variations mensuelles sont souvent plus stationnaires que les niveaux. Une transformation logarithmique a également été appliquée afin de stabiliser la variance de la série, souvent hétéroscédastique dans le cas d’indices boursiers.

Le modèle est estimé sur la période allant de janvier 2000 à décembre 2018. Les résultats montrent que le paramètre Theta(1) est estimé à 0.14893, avec une erreur standard de 0.06566. Ce paramètre est statistiquement significatif au seuil de 5 %, comme l’indique une p-value de 0.0243. La significativité de ce terme suggère que les chocs passés ont un effet direct sur l’évolution présente de la série, ce qui est cohérent avec le comportement souvent persistant des rendements boursiers.

Le modèle inclut un seul événement exceptionnel : un outlier de type additif (AO) en septembre 2002. Son coefficient, estimé à -0.15439 avec un t-stat de -4.925, est hautement significatif. Ce type de rupture représente une variation brutale et ponctuelle du niveau de la série, sans effet persistant au-delà de la période concernée. Une telle chute peut correspondre à un événement économique ou financier isolé ayant fortement influencé le marché ce mois-là.

Le modèle ne retient ni effet de calendrier (pas de jours ouvrables, pas d’effet Pâques ni d’année bissextile), ni constante. L’absence d’effets calendaires implique que la dynamique de la série ne semble pas influencée de manière systématique par ces composantes, du moins sur la période étudiée. Cela peut s’expliquer par la nature des données financières, où les effets saisonniers sont moins marqués qu’en démographie ou dans les ventes de détail.

Enfin, l’ajustement du modèle est satisfaisant, comme en témoigne l’erreur standard des résidus de 0.04784 et les 224 degrés de liberté. Les critères d’information sont cohérents avec une modélisation parcimonieuse : l’AIC est de 3068, l’AIC corrigé identique, et le BIC corrigé pour la longueur est de -6.032. Ce BIC légèrement négatif peut être interprété comme le résultat d’une vraisemblance relativement élevée combinée à une pénalisation plus forte sur le nombre de paramètres et la taille de l’échantillon. La comparaison des transformations montre que le modèle avec transformation logarithmique est préféré à celui sans transformation, le critère AIC ayant été amélioré de deux points. Cela confirme la pertinence de la transformation log pour améliorer la qualité de l’ajustement.


### 1. Suppression du point atypique

```{r}
cac40 <- cac40 |>
  filter(date != "2002-09-30")

cac40_ts <- ts(
  data = cac40$cloture, 
  start = c(2000, 01), 
  frequency = 12
)
```

```{r}
## X13 method
myregx13 <- regarima_x13(cac40_ts, spec = "RG5c")
summary(myregx13)
s_transform(myregx13)
# plot(myregx13)
```

Aucun autre point atypique détecté


### 2. Transformation logarithmique

```{r}
log_cac40_ts <- log(cac40_ts)
log_cac40_prev_ts <- log(cac40_prev_ts)
```

```{r}
## X13 method
myregx13 <- regarima_x13(log_cac40_ts, spec = "RG5c")
summary(myregx13)
s_transform(myregx13)
# plot(myregx13)
```

Plus de transformation


### 3. Saisonnalité

```{r}
# Seasonal dummies
library(TSA)
library(seastests)
sd <- seasdum(log_cac40_ts)
show(sd)
```

Le test des variables muettes saisonnières (seasdum) a été appliqué à la série temporelle log_cac40_ts afin de détecter la présence d’une composante saisonnière. La statistique de test obtenue est de 0,98, avec une p-value associée de 0,4649234. Cette p-value étant supérieure aux seuils usuels de signification (5 % ou même 10 %), on ne rejette pas l’hypothèse nulle d’absence de saisonnalité. Cela signifie qu’il n’existe pas de preuve statistique suffisante pour affirmer que la série CAC 40 présente une variation régulière et récurrente selon les périodes (mois, trimestres, etc.).


```{r}
# Webel-Ollech test
wot <- combined_test(log_cac40_ts)
show(wot)
```

Le test combiné de type WO (Webel-Ollech) a été réalisé sur la série log_cac40_ts afin de détecter d’éventuels effets saisonniers ou calendaires. La statistique de test obtenue est 0, ce qui indique l'absence d’effet saisonnier détecté par le test. Les p-values associées aux différents sous-tests (1, 1, et 0.538) sont toutes bien supérieures au seuil classique de 5 %, ce qui signifie que l’on ne rejette pas l’hypothèse nulle d’absence de saisonnalité. En conclusion, le test ne met pas en évidence de structure saisonnière ou calendaire significative dans la série analysée.



## c. Vérifier la stationnarité de la série I(0) ou I(1)

### 1. Tests

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  log_cac40_ts,
  type = "drift",
  selectlags = "AIC"
)
summary(adf_test)
```

Le test de Dickey-Fuller Augmenté (ADF) a été appliqué à la série logarithmique du CAC40 pour évaluer la présence d’une racine unitaire, indicatrice de non-stationnarité. La statistique de test obtenue est de -2.3814, tandis que les valeurs critiques aux seuils de 1%, 5% et 10% sont respectivement -3.46, -2.88 et -2.57. Étant donné que la statistique est supérieure à ces seuils, nous ne pouvons pas rejeter l’hypothèse nulle de non-stationnarité. Ce résultat suggère donc que la série n’est pas stationnaire selon ce test.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  log_cac40_ts,
  type = "Z-tau",
  model = "constant",
  lags = "long"
)
summary(pp_test)
```

Le test de Phillips-Perron (PP), qui vise également à détecter une racine unitaire tout en étant plus robuste à l’hétéroscédasticité, a fourni une statistique de test Z-tau de -2.3974. Cette valeur reste supérieure aux valeurs critiques à 1%, 5% et 10%, qui sont respectivement -3.4606, -2.8744 et -2.5736. Ainsi, l’hypothèse nulle de racine unitaire n’est pas rejetée, ce qui confirme le résultat du test ADF et indique également une non-stationnarité de la série.


#### 3. Test de KPSS

```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  log_cac40_ts,
  type = "mu",
  lags = "long"
)
summary(kpss_test)
```

Le test KPSS fonctionne à l’inverse des deux précédents en testant l’hypothèse nulle de stationnarité. Pour notre série, la statistique de test est de 0.1383, nettement inférieure aux valeurs critiques à 10%, 5%, 2.5% et 1% (0.347, 0.463, 0.574 et 0.739 respectivement). Dans ce cas, on ne rejette pas l’hypothèse nulle de stationnarité, ce qui contraste avec les conclusions des tests ADF et PP.


#### 4. Conclusion

Les résultats des tests unitaires sont contradictoires. Alors que les tests ADF et PP ne rejettent pas l’hypothèse de non-stationnarité, le test KPSS n’invalide pas l’hypothèse de stationnarité. Cette divergence peut être le signe que la série est proche d’un comportement de racine unitaire ou que certains effets limites (comme un bruit élevé ou un choix de modèle inadapté) faussent les résultats. Face à cette divergence, il est pertinent de différencier la série et de réévaluer sa stationnarité.


### 2. Différenciation de la série

```{r}
# 1. Différencier la série
diff_log_cac40_ts <- diff(log_cac40_ts)
ts.plot(diff_log_cac40_ts)
```

Afin de corriger la non-stationnarité détectée par les tests ADF et PP, nous avons appliqué une différenciation première à la série logarithmique du CAC40. Cette transformation permet de stabiliser la moyenne de la série et d’atténuer les effets de tendance.


### 3. Tester la stationnarité après différenciation

#### 1. Test de Dickey-Fuller Augmenté (ADF)

```{r}
# Test de Dickey-Fuller augmenté
adf_test <- ur.df(
  diff_log_cac40_ts,
  type = "none",
  selectlags = "AIC"
)
summary(adf_test)
```

Après différenciation, la statistique de test ADF est de -10.3616, ce qui est largement inférieur aux valeurs critiques à 1%, 5% et 10% (-2.58, -1.95, -1.62). Ce résultat très significatif nous permet de rejeter fermement l’hypothèse nulle de non-stationnarité. Ainsi, la série différenciée est stationnaire selon le test ADF.


#### 2. Test de Philips et Perron (PP)

```{r}
# Test de Philips et Perron
pp_test <- ur.pp(
  diff_log_cac40_ts,
  type = "Z-tau",
  model = "constant",
  lags = "short"
)
summary(pp_test)
```

Le test PP appliqué à la série différenciée donne une statistique Z-tau de -13.3474, une valeur également très inférieure aux seuils critiques de -3.4607, -2.8744 et -2.5736. Cela confirme que l’hypothèse de racine unitaire est nettement rejetée, et que la stationnarité est bien atteinte après transformation.


#### 3. Test de KPSS

```{r}
# Test de KPSS
kpss_test <- ur.kpss(
  diff_log_cac40_ts,
  type = "mu"
)
summary(kpss_test)
```

Le test KPSS retourne une statistique de 0.1189, largement en dessous des seuils critiques à 10%, 5%, 2.5% et 1% (0.347, 0.463, 0.574, 0.739). On ne rejette donc pas l’hypothèse de stationnarité, ce qui vient confirmer les résultats des tests ADF et PP.


#### 4. Conclusion

Les trois tests convergent désormais vers une même conclusion : la série devient stationnaire après différenciation. Les tests ADF et PP rejettent l’hypothèse de racine unitaire, tandis que le test KPSS valide la stationnarité. Par conséquent, la transformation appliquée permet de rendre la série adaptée à des analyses économétriques plus avancées.


### 4. Corrélogrammes

```{r}
library(gridExtra)

# Corrélogramme

acf_graph1 <- log_cac40_ts |>
  ggAcf() +
  ggtitle("Corrélogramme sur la série en niveau") +
  theme_bw()

acf_graph2 <- diff_log_cac40_ts |>
  ggAcf() +
  ggtitle("Corrélogramme sur la série en différence première") +
  theme_bw()

grid.arrange(acf_graph1, acf_graph2, ncol = 2)
```

Avant la différenciation, la série, non stationnaire (comme une série intégrée I(1)), présente une autocorrélation significative sur les premiers retards, ce qui suggère la présence d'une racine unitaire et l'absence de stationnarité. Après la différenciation, l'ACF montre une légère autocorrélation au quatrième retard, avec des autocorrélations non significatives pour les autres retards, ce qui indique que la série est devenue stationnaire (I(0)). Ainsi, l'ACF de la série différenciée ne présente plus d'autocorrélations significatives, à l'exception d'une autocorrélation résiduelle éventuelle au quatrième retard, suggérant que la différenciation a éliminé la non-stationnarité, rendant la série adaptée à des analyses économétriques.


## d. Statistiques descriptives (moyenne, écart-type, skewness, kurtosis normalité, box-plot …). (cf. Chapitre 3 p38) Commenter

### 1. Statistiques

```{r}
library(fBasics)

stats <- basicStats(log_cac40_ts)
show(stats)
```


### 2. Normalité

```{r}
shapiro.test(diff_log_cac40_ts)
```

La p-value de 0.003368, inférieure au seuil de 5 %, indique que l'hypothèse nulle de normalité est rejetée au seuil de risque de 5 %. Cela signifie que les données ne suivent pas une distribution normale. Ainsi, la série différenciée du CAC 40 n'est pas normalement distribuée d'après le test de Shapiro-Wilk.


### 3. Boîte à moustache

```{r}
boxplot(
  log_cac40_ts,
  main = "Boîte à moustaches de la série",
  ylab = "Valeurs",
  col = "lightblue"
)
```

```{r}
log_cac40_ts |>
  as.numeric() |>
  tibble(valeurs = _) |>
  ggplot(aes(x = valeurs, y = "")) +
  geom_violin(fill = "white", color = "black") +
  geom_boxplot(
    width = 0.5, fill = "grey", outlier.color = "red",
    outlier.size = 2, staplewidth = 0.4
  ) +
  labs(
    title = "Visualisation de la distribution des valeurs de log(CAC 40)",
    x = "Valeurs",
    y = "Distribution"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    axis.title.y = element_text(size = 14),
    axis.title.x = element_text(size = 14),
    axis.text.x = element_text(size = 12)
  )
```





# 2. Estimation des modèles linéaires

## a. Estimer et commenter les paramètres des modèles AR(1), AR(p) et ARIMA(p,d,q) et de la méthode LED Holt-Winters, ADAM ETS, ADAM ETS ARIMA, SSARIMA et CES 


### 2.1 - Autoarima

```{r}
mod_arima <- auto.arima(log_cac40_ts)
summary(mod_arima)
```


### 2.2 - Lissage Exponentiel Double (LED) de Holt-Winters

```{r}
# ---- Modélisation ----

# Modèle LED Holt-Winters : lissage exponentiel double (niveau + tendance)
m <- HoltWinters(log_cac40_ts, gamma = FALSE)

# ---- prévision ----

# Prévision sur un horizon h = 12 avec intervalles de confiance à 80% et 95%
fit <- forecast(m, h = 12) # ← prévision à 12 périodes
plot(fit)
show(fit)

# Prévisions ponctuelles
prevf <- fit$mean # ← point de prévision
show(prevf)

# Informations sur le modèle ajusté
mod <- fit$model
show(mod)


```
#### 2.2.1 - AIC de Holtwinters

```{r}
# Nombre d'observations
n <- length(m$fitted[,1])

# Somme des carrés des résidus
RSS <- sum(residuals(m)^2)

# Nombre de paramètres estimés (alpha + beta, pas de gamma ici)
k <- 2

# Calcul manuel de l'AIC
aic_hw <- n * log(RSS / n) + 2 * k
cat("AIC du modèle Holt-Winters (niveau + tendance) :", round(aic_hw, 2), "\n")

```


### 2.3 - ADAM ETS (Error-Trend-Seasonal)

```{r}
# Chargement de la librairie
library(smooth)

# Estimation du modèle ADAM ETS (ZZZ = sélection automatique)
fit_adam_ets <- auto.adam(
  log_cac40_ts,              # série mensuelle CAC 40
  model = "ZZN",         # sélection automatique de la structure ETS
  lags = c(1, 12),       # court terme et saisonnalité mensuelle
  select = TRUE          # sélection selon l'AIC
)

# Prévision à 12 mois avec intervalle de confiance à 90 %
prev_adam_ets <- forecast(fit_adam_ets, h = 12, level = 0.90)

# Affichage des prévisions
plot(prev_adam_ets)

# Aperçu des valeurs prédites
prev_adam_ets

```
#### 2.3.1 - AIC de ADAM ETS 

```{r}
aic_adam <- AIC(fit_adam_ets)
cat("AIC du modèle ADAM ETS :", round(aic_adam, 2), "\n")
```

### 2.4 - ADAM ETS-ARIMA (modèle hybride)

```{r}
# Modèle ADAM ETS + ARIMA
library(smooth)

fit_adam_ets_arima <- auto.adam(
  log_cac40_ts,                          # série CAC 40 en niveau
  model = "ZZN",                     # sélection automatique ETS
  lags = c(1, 1, 12),                # lags pour tendance, ARIMA, saisonnalité
  orders = list(
    ar = c(3, 3),                    # ordres AR non saisonnier / saisonnier
    i  = c(2),                       # ordre de différenciation
    ma = c(3, 3)                     # ordres MA non saisonnier / saisonnier
  ),
  select = TRUE                     # sélection automatique du meilleur sous-modèle
)

# Prévision sur 12 mois avec IC à 90 %
prev_adam_ets_arima <- forecast(fit_adam_ets_arima, h = 12, level = 0.90)

# Affichage des prévisions
prev_adam_ets_arima
plot(prev_adam_ets_arima)

```

#### 2.4.1 - AIC de ADAM ETS+ARIMA
```{r}
aic_adam_ets_arima <- AIC(fit_adam_ets_arima)
cat("AIC du modèle ADAM ETS+ARIMA :", round(aic_adam_ets_arima, 2), "\n")
```

### 2.5 - SSARIMA (State Space ARIMA)

```{r}
# Modèle SSARIMA
library(smooth)

fitssarima <- auto.ssarima(
  log_cac40_ts, # série utilisée
  lags = c(1, 12), # spécifie une structure SARIMA mensuelle
  orders = list(
    ar = c(3, 3), # ordre max AR non saisonnier et saisonnier
    i = c(2), # ordre max de différenciation
    ma = c(3, 3)
  ), # ordre max MA non saisonnier et saisonnier
  select = TRUE # sélection automatique du meilleur modèle
)

summary(fitssarima)

# Graphiques
par(mfcol = c(2, 2))
plot(fitssarima)

# Prévision sur 12 mois (avec IC à 90 %)
prevssarima <- forecast(fitssarima, h = 12, level = 0.90) # ← prévision du modèle SSARIMA pour h = 12
plot(prevssarima)
```





# 3. Prévision linéaire sur une année 

## Estimation jusqu'a 2018
```{r}


# Estimation des modèles sur la base d'apprentissage (jusqu’à 2018)
fit_adam_2018 <- auto.adam(log_cac40_ts, model = "ZZN", lags = c(1, 12), select = TRUE)
fit_adamarima_2018 <- auto.adam(log_cac40_ts, model = "ZZN", lags = c(1, 1, 12),
orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_arima_2018 <- auto.arima(log_cac40_ts)
fit_hw_2018 <- HoltWinters(log_cac40_ts, gamma = FALSE)
fit_ssarima_2018 <- auto.ssarima(log_cac40_ts, lags = c(1, 12),
                                 orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)


```

## Prévision sur 12 mois en 2019
```{r}
# Prévision à 12 mois
h <- 12
prev_adam_2019       <- forecast(fit_adam_2018, h = h)
prev_adamarima_2019  <- forecast(fit_adamarima_2018, h = h)
prev_arima_2019      <- forecast(fit_arima_2018, h = h)
prev_hw_2019         <- forecast(fit_hw_2018, h = h)
prev_ssarima_2019    <- forecast(fit_ssarima_2018, h = h)
plot(prev_adam_2019)
```

## Résultats 
```{r}
# Créer l’axe des dates pour 2019
dates_2019 <- seq(as.Date("2019-01-01"), by = "month", length.out = 12)

# Regrouper toutes les prévisions + la série réalisée
df_forecast_2019 <- tibble(
  Date = rep(dates_2019, times = 6),
  Valeur = c(
    as.numeric(prev_adam_2019$mean),
    as.numeric(prev_adamarima_2019$mean),
    as.numeric(prev_arima_2019$mean),
    as.numeric(prev_hw_2019$mean),
    as.numeric(prev_ssarima_2019$mean),
    as.numeric(log_cac40_prev_ts)
  ),
  Modèle = rep(c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA", "Réalisation"), each = 12)
)

# Affichage d'un aperçu
print(df_forecast_2019, n = Inf)

View(df_forecast_2019)
view(log_cac40_ts)
view(log_cac40_prev_ts)

```





# 4. Représentation graphique des différents modèles 

```{r}
library(tidyverse)
library(ggplot2)

# On suppose que vous avez déjà créé le tibble df_forecast_2019 avec les colonnes :
# Date, Valeur, Modèle

# Graphique des prévisions comparées à la série réalisée
ggplot(df_forecast_2019, aes(x = Date, y = Valeur, color = Modèle)) +
  geom_line(size = 1.2) +
  labs(
    x = "Date",
    y = "Indice CAC 40"
  ) +
  theme_minimal(base_size = 13) +
  scale_color_manual(values = c(
    "ADAM.ETS" = "#E76F51",
    "ADAM.ETS.ARIMA" = "#9D4EDD",
    "ARIMA" = "#277DA1",
    "Holt-Winters" = "#2A9D8F",
    "SSARIMA" = "#F72585",
    "Réalisation" = "black"
  )) +
  theme(legend.title = element_blank())

```





# 5. Qualité de prévision 


## 5.1 -  MSE et R2oo

```{r}
# Nouvelle série d'apprentissage : jusqu’à fin 2018
cac40_train <- window(log_cac40_ts, end = c(2018, 12))

# Série de test : l’année 2019
cac40_test  <- log_cac40_prev_ts


# Ré-estimation des modèles sur la nouvelle série d'apprentissage
fit_adam <- auto.adam(log_cac40_ts, model = "ZZN", lags = c(1, 12), select = TRUE)
fit_adamarima <- auto.adam(log_cac40_ts, model = "ZZN", lags = c(1, 1, 12),
                           orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)
fit_arima <- auto.arima(log_cac40_ts)
fit_hw <- HoltWinters(log_cac40_ts, gamma = FALSE)
fit_ssarima <- auto.ssarima(log_cac40_ts, lags = c(1, 12),
                            orders = list(ar = c(3, 3), i = c(2), ma = c(3, 3)), select = TRUE)


# Prévision sur 12 mois (année 2019)
h <- 12
prev_adam       <- forecast(fit_adam, h = h)
prev_adamarima  <- forecast(fit_adamarima, h = h)
prev_arima      <- forecast(fit_arima, h = h)
prev_hw         <- forecast(fit_hw, h = h)
prev_ssarima    <- forecast(fit_ssarima, h = h)


```

```{r}
# MSE
mse_adam      <- mean((log_cac40_prev_ts - prev_adam$mean)^2)
mse_adamarima <- mean((log_cac40_prev_ts - prev_adamarima$mean)^2)
mse_arima     <- mean((log_cac40_prev_ts - prev_arima$mean)^2)
mse_hw        <- mean((log_cac40_prev_ts - prev_hw$mean)^2)
mse_ssarima   <- mean((log_cac40_prev_ts - prev_ssarima$mean)^2)


# R² OOS
r2_adam       <- 1 - (mse_adam / mse_arima)
r2_adamarima  <- 1 - (mse_adamarima / mse_arima)
r2_hw         <- 1 - (mse_hw / mse_arima)
r2_ssarima    <- 1 - (mse_ssarima / mse_arima)


```


```{r}
tibble(
  Modèle       = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA"),
  MSE          = c(mse_adam, mse_adamarima, mse_arima, mse_hw, mse_ssarima),
  R2_OOS       = c(r2_adam, r2_adamarima, NA, r2_hw, r2_ssarima)
)
```

## 5.2 - Prédiction naïve

```{r}
# --- Prévision naïve : moyenne de la série d'apprentissage (benchmark alternatif) ---
naive_forecast <- naive(log_cac40_ts,h=12)
naive_forecast <- as.numeric(naive_forecast$mean)
log_cac40_prev_ts <- as.numeric(log_cac40_prev_ts)

mse_naive <- mean((log_cac40_prev_ts - naive_forecast)^2)

#view(mse_naive)

# --- R² OOS par rapport à la prévision naïve ---
r2_adam_naive       <- 1 - (mse_adam / mse_naive)
r2_adamarima_naive  <- 1 - (mse_adamarima / mse_naive)
r2_arima_naive      <- 1 - (mse_arima / mse_naive)
r2_hw_naive         <- 1 - (mse_hw / mse_naive)
r2_ssarima_naive    <- 1 - (mse_ssarima / mse_naive)



# --- Tableau résumé avec comparaison au benchmark naïf ---
tibble(
  Modèle          = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA"),
  MSE = c(mse_adam, mse_adamarima, mse_arima, mse_hw, mse_ssarima),
  R2_OOS_naive    = c(r2_adam_naive, r2_adamarima_naive, r2_arima_naive, r2_hw_naive, r2_ssarima_naive)
)
mse_naive

mean(cac40_train)

```




## 5.3 -  Erreurs de prévision cumulées au carré (CSPE)

```{r}
library(tibble)

errors_cumul <- tibble(
  Mois = rep(1:12, times = 5),
  Erreur_carrée = c(
    ( log_cac40_prev_ts- prev_adam$mean)^2,
    (log_cac40_prev_ts - prev_adamarima$mean)^2,
    (log_cac40_prev_ts - prev_arima$mean)^2,
    (log_cac40_prev_ts - prev_hw$mean)^2,
    (log_cac40_prev_ts - prev_ssarima$mean)^2
  ),
  Modèle = rep(c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA"), each = 12)
)


# Calcul de l’erreur cumulée
errors_cumul <- errors_cumul %>%
  group_by(Modèle) %>%
  mutate(Erreur_cum = cumsum(Erreur_carrée))

# Graphique des erreurs cumulées
ggplot(errors_cumul, aes(x = Mois, y = Erreur_cum, color = Modèle)) +
  geom_line(size = 1.2) +
  labs(
    x = "Mois",
    y = "Erreur cumulée",
    color = "Modèle"
  ) +
  theme_minimal(base_size = 13)

```




cac40_test  <- log_cac40_prev_ts
# 6. Test de précision


```{r}
# Erreurs de prévision
err_adam       <- log_cac40_prev_ts - prev_adam$mean
err_adamarima  <- log_cac40_prev_ts- prev_adamarima$mean
err_arima      <- log_cac40_prev_ts - prev_arima$mean
err_hw         <- log_cac40_prev_ts - prev_hw$mean
err_ssarima    <- log_cac40_prev_ts - prev_ssarima$mean

# Prévision naïve : moyenne constante
naive_forecast 
err_naive      <- log_cac40_prev_ts - naive_forecast

```


```{r}
# Tests DM : modèle vs prévision naïve (h = 1 car horizon = 1 par point)
dm_adam <- dm.test(err_adam, err_naive, h = 1, alternative = "less")
dm_adamarima <- dm.test(err_adamarima, err_naive, h = 1, alternative = "less")
dm_arima <- dm.test(err_arima, err_naive, h = 1, alternative = "less")
dm_hw <- dm.test(err_hw, err_naive, h = 1, alternative = "less")
dm_ssarima <- dm.test(err_ssarima, err_naive, h = 1, alternative = "less")
```



```{r}
library(tibble)

tibble(
  Modèle = c("ADAM.ETS", "ADAM.ETS.ARIMA", "ARIMA", "Holt-Winters", "SSARIMA"),
  p_value_DM_naive = c(
    dm_adam$p.value,
    dm_adamarima$p.value,
    dm_arima$p.value,
    dm_hw$p.value,
    dm_ssarima$p.value
  )
)

```






# 7. Prévision à 1 pas du meilleur modèle de la question 6

```{r}
library(smooth)
library(tibble)
library(ggplot2)

# Initialisation du vecteur de prévisions
pred_rolling_adam <- numeric(12)

# Boucle sur les 12 mois de 2019
for (i in 1:12) {
  # Déterminer la date de fin pour l’échantillon d’estimation
  end_year <- 2018 + floor((i - 1) / 12)
  end_month <- (i - 1) %% 12 + 1
  train_ts <- window(log_cac40_ts, end = c(end_year, end_month))
  
  # Ré-estimation du modèle ADAM.ETS
  fit <- auto.adam(
    train_ts,
    model = "ZZN",
    lags = c(1, 12),
    select = TRUE
  )
  
  # Prévision à 1 mois
  pred <- forecast(fit, h = 1)
  pred_rolling_adam[i] <- pred$mean[1]
}

# Création du tibble avec les dates de 2019
dates_rolling <- seq(as.Date("2019-01-01"), by = "month", length.out = 12)

df_rolling <- tibble(
  Date = dates_rolling,
  Prévision = pred_rolling_adam,
  Réalisé = as.numeric(log_cac40_prev_ts)
)

# Affichage du tableau
print(df_rolling)

ggplot(df_rolling, aes(x = Date)) +
  geom_line(aes(y = Réalisé, color = "Réalisation"), size = 1.2) +
  geom_line(aes(y = Prévision, color = "Prévision glissante"), size = 1.2) +
  labs(
    x = "Date", y = "Valeurs en log",
    title = "Prévision glissante à 1 mois (ADAM.ETS)"
  ) +
  scale_color_manual(values = c("Réalisation" = "black", "Prévision glissante" = "blue")) +
  theme_minimal(base_size = 13) +
  theme(legend.title = element_blank())

```


FLO

```{r}
library(smooth)

# Initialisation
estimation <- log_cac40_ts

# Prévisions pour 12 périodes
prevision <- map_dbl(1:12, function(i) {
  
  # Ajout de la dernière valeur observée avant la prévision
  if (i > 1) {
    estimation <- ts(
      c(log_cac40_ts, log_cac40_prev_ts_ts[1:(i - 1)]), 
      frequency = 12
    )
  }
  
  # Prévision à un pas
  forecast(
    auto.adam(
      estimation,
      model = "ZZN",
      lags = c(1, 12),
      orders = list(ar = c(3, 3), i = 2, ma = c(3, 3), select = TRUE)
    ), 
    h = 1, 
    level = 0.90
  )$mean[1]
})

prevision
```


```{r}
# Dataframe avec les dates, les prévisions du modèle et les réalisations

df <- tibble(
  Date = cac40_prev$date,
  Prévision = prevision,
  Réalisation = log(cac40_prev$cloture)
)


# Graphique

df |> 
  ggplot() +
  aes(x = Date) +
  geom_line(aes(y = Prévision, color = "Prévision"), size = 1) +
  geom_line(aes(y = Réalisation, color = "Réalisation"), size = 1) +
  labs(
    title = "Comparaison des prévisions et des réalisations",
    x = "Date",
    y = "Valeur",
    color = "Série"
  ) +
  scale_color_manual(values = c("Prévision" = "blue", "Réalisation" = "red")) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```
